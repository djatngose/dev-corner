
# Object Tracking
A DbContext instance keeps track of all the entities it instantiates, so it can feed the same ones back to you whenever you request the same rows in a table. In other words, a context in its lifetime will never emit two separate entities that refer to the same row in a table (where a row is identified by primary key). This capability is called object tracking.

To illustrate, suppose the customer whose name is alphabetically first also has the lowest ID. In the following example, a and b will reference the same object:
```c#
using var dbContext = new NutshellContext ();

Customer a = dbContext.Customers.OrderBy (c => c.Name).First();
Customer b = dbContext.Customers.OrderBy (c => c.ID).First();
```
`DISPOSING DBCONTEXT`
Although DbContext implements IDisposable, you can (in general) get away without disposing instances. Disposing forces the context’s connection to dispose—but this is usually unnecessary because EF Core closes connections automatically whenever you finish retrieving results from a query.

`Explanation above code:`
```c#
public void MyMethod()
{
    IQueryable<Customer> customers = GetCustomers("a");

    // Other code here

    // Loop over the customers and print their names
    foreach (Customer c in customers)
    {
        Console.WriteLine(c.Name);
    }

    // Other code here
}

```
When MyMethod is executed, the following happens:

  1. The GetCustomers method is called, which creates a new dbContext and returns an IQueryable<Customer> object representing a query against the database.
  2. The dbContext is wrapped in a using statement, which ensures that it will be disposed of once the GetCustomers method completes.
  3. The IQueryable<Customer> object is assigned to the customers variable in MyMethod.
  4. Other code executes in MyMethod.
  5. The foreach loop is reached, which attempts to execute the query represented by the customers variable.
  6. At this point, the dbContext has already been disposed of, since it was wrapped in a using statement and was disposed of when the GetCustomers method completed.
  7. Because the dbContext has been disposed of, the query represented by the customers variable cannot be executed, and an error occurs.

So, the issue here is that the dbContext is disposed of before the foreach loop can execute the query and retrieve data from the database.

There are `some caveats, though, on not disposing contexts:`

  - It relies on the connection object releasing all unmanaged resources on the Close method. Even though this holds true with SqlConnection, it’s theoretically possible for a third-party connection to keep resources open if you call Close but not Dispose (though this would arguably violate the contract defined by IDbConnection.Close).
  - If you manually call GetEnumerator on a query (instead of using foreach) and then fail to either dispose the enumerator or consume the sequence, the connection will remain open. Disposing the DbContext provides a backup in such scenarios.
  - Some people feel that it’s tidier to dispose contexts (and all objects that implement IDisposable).

If you want to explicitly dispose contexts, you must pass a DbContext instance into methods such as GetCustomers to avoid the problem described. In scenarios such as ASP.NET Core MVC where the context instance is provided via dependency injection (DI), the DI infrastructure will manage the context lifetime. It will be created when a unit of work (such as an HTTP request processed in the controller) begins and disposed when that unit of work ends.

For example, in an ASP.NET Core MVC application, you might register the DbContext with the DI container in the ConfigureServices method of your Startup class, like this:

```c#
public void ConfigureServices(IServiceCollection services)
{
    services.AddDbContext<MyDbContext>(options =>
        options.UseSqlServer(Configuration.GetConnectionString("MyConnectionString"))); // scope lifetime
}
```
Once the DbContext is registered with the DI container, it can be injected into controllers and other classes that need it, like this:

```c#
public class MyController : Controller
{
    private readonly MyDbContext _dbContext;

    public MyController(MyDbContext dbContext)
    {
        _dbContext = dbContext;
    }

    public IActionResult MyAction()
    {
        IQueryable<Customer> customers = _dbContext.Customers.Where(c => c.Name.StartsWith("a"));

        foreach (Customer c in customers)
        {
            Console.WriteLine(c.Name);
        }

        return View();
    }
}
```
In this case, the MyDbContext instance is injected into the MyController constructor by the DI container. This ensures that the DbContext is created and disposed of properly for each HTTP request processed by the controller.

So, the main takeaway is that you need to carefully manage the lifetime of the DbContext instance to ensure that it is created and disposed of properly. Depending on the architecture of your application, you may need to pass the DbContext around explicitly as a parameter, or use a DI container to manage its lifetime for you.


# Using a singleton instance of DbContext cause concurrency and data integrity issues?
Using a singleton instance of DbContext across the application can cause concurrency and data integrity issues because the same instance of DbContext is shared across all requests and threads. This means that if two requests are accessing the same DbContext instance at the same time, they may interfere with each other and cause unexpected behavior.

For example, if one request updates a record in the database while another request is reading the same record, the second request may not see the updated data, because it is still working with a stale copy of the data from the DbContext cache. This can lead to data integrity issues and inconsistent behavior.

In addition, DbContext instances are not thread-safe by default, which means that multiple threads accessing the same DbContext instance concurrently can lead to race conditions and other synchronization issues.

To avoid these issues, it is recommended to use a scoped instance of DbContext, which is created and disposed of for each HTTP request in a web application. This ensures that each request has its own instance of DbContext, which is not shared with other requests and is therefore less prone to concurrency issues.

AddDbContextPool is a method provided by Entity Framework Core to add a scoped instance of DbContext to the DI container, and it provides better performance than using AddDbContext with a scoped lifetime. However, it should be used with caution and only when necessary, as it can introduce new issues if not used correctly.

# WHen to use AddDbContextPool?

You can use AddDbContextPool instead of AddDbContext in situations where you need to create and dispose of multiple instances of DbContext within a single HTTP request.

By default, AddDbContext registers the DbContext as a scoped service, which means that a new instance of the DbContext is created and disposed of for each HTTP request. While this is generally sufficient for most scenarios, there are situations where you might need to create and dispose of multiple instances of DbContext within a single HTTP request, such as when you have long-running tasks that need to access the database.

AddDbContextPool is designed for these scenarios, and it registers the DbContext as a pooled service, which means that multiple instances of the DbContext are created and cached in a pool. When a request needs to access the database, it can retrieve an instance of the DbContext from the pool, and when it's finished, it returns the DbContext instance to the pool. This can improve performance by reducing the overhead of creating and disposing of DbContext instances.

However, it's important to note that AddDbContextPool should only be used when you need to create and dispose of multiple instances of DbContext within a single HTTP request. If you only need a single instance of DbContext per request, then you should use AddDbContext instead. Additionally, you should be careful when using AddDbContextPool with long-running tasks, as it can introduce issues with data consistency and concurrency if not used correctly.

# Here are a few common scenarios where you might want to use AddDbContextPool in a real-life application:

`Web applications with heavy database usage`: If your web application heavily relies on database access and you have a large number of concurrent requests, you may benefit from using a pooled DbContext to improve performance. By using a pool of DbContext instances, you can reduce the overhead of creating and disposing of DbContext instances for each request, which can help improve response times and reduce server load.

`Long-running background tasks`: If you have long-running background tasks that need to access the database, such as batch jobs or data processing tasks, you may want to use a pooled DbContext to manage database connections. By using a pool of DbContext instances, you can avoid creating too many connections to the database, which can cause performance issues and limit the scalability of your application.

`Multi-tenant applications`: If you're building a multi-tenant application where each tenant has their own database, you may want to use a pool of DbContext instances to manage database connections for each tenant. By using a pool of DbContext instances, you can avoid creating too many connections to the database for each tenant, which can help improve the scalability of your application.

`Applications with high traffic spikes`: If your application experiences high traffic spikes, you may want to use a pool of DbContext instances to handle the increased load. By using a pool of DbContext instances, you can avoid creating too many connections to the database during peak traffic periods, which can help prevent database connection errors and improve the overall performance of your application.

In general, if you have a high volume of database access and you're looking to improve performance and scalability, using a pooled DbContext with AddDbContextPool can be a good option to consider.

`Consider what happens when EF Core encounters the second query`. It starts by querying the database—and obtaining a single row. It then reads the primary key of this row and performs a lookup in the context’s entity cache. Seeing a match, it returns the existing object without updating any values. So, if another user had just updated that customer’s Name in the database, the new value would be ignored. This is essential for avoiding unexpected side effects (the Customer object could be in use elsewhere) and also for managing concurrency. If you had altered properties on the Customer object and not yet called `SaveChanges`, you wouldn’t want your properties automatically overwritten.
  - When EF Core encounters a query that fetches an entity from the database, it will first perform the database query and retrieve the entity's values from the database. It will then look in the context's entity cache to see if it already has an entity with the same primary key. If it finds a match, it will return the cached entity rather than creating a new one. This helps to prevent unexpected side effects by ensuring that all parts of the application are working with the same instance of the entity.
  - However, this approach also has implications for managing concurrency. If another user had just updated the same entity in the database, the cached entity in the context's entity cache may be out of date. If EF Core were to automatically update the cached entity with the new values from the database, it could inadvertently overwrite changes made to the entity by the current user. To prevent this, EF Core does not automatically update cached entities with values from the database.
  - Instead, if you want to update an entity with the latest values from the database, you need to explicitly `reload` the entity from the database using the Reload method or by querying for the entity again. This gives you control over when to update the entity's values and helps to prevent unexpected data loss or concurrency issues.

`NOTE`
You can disable object tracking by chaining the AsNoTracking extension method to your query or by setting ChangeTracker.QueryTrackingBehavior on the context to QueryTrackingBehavior.NoTracking. No-tracking queries are useful when data is used read-only as it improves performance and reduces memory use.

To get fresh information from the database, you must either instantiate a new context or call the Reload method, as follows:
```c#
dbContext.Entry (myCustomer).Reload();
```
The `best practice is to use a fresh DbContext instance per unit of work so that the need to manually reload an entity is rare.`

# When to use QueryTrackingBehavior.NoTracking and not?

`QueryTrackingBehavior` is an enumeration in EF Core that controls whether or not entities returned by a query are tracked by the context. When entities are tracked, any changes made to those entities will be detected by the context and persisted to the database when SaveChanges is called. When entities are not tracked, changes made to those entities will not be detected by the context.

There are a few scenarios where you might want to use `QueryTrackingBehavior.NoTracking`:

  - Performance: If you are performing read-only operations and don't need to track changes to entities, using NoTracking can provide a performance boost by reducing the overhead of tracking changes.
  - Large data sets: If you are querying a large data set, tracking all of the entities returned by the query can consume a lot of memory. Using NoTracking can reduce the memory overhead by not tracking the entities.
  - Disconnected scenarios: If you are working in a disconnected scenario (such as a web application) where the context is short-lived and you don't need to track changes to entities across requests, using NoTracking can simplify your code by avoiding the need to detach entities from the context before returning them to the client.
  - Read-heavy queries: If you are executing read-heavy queries that return a large number of entities, it can be more efficient to use QueryTrackingBehavior.NoTracking. This can reduce the amount of memory required to track the entities and improve query performance.
  - Caching data: If you are caching data in your application, using QueryTrackingBehavior.NoTracking can be a good option to avoid caching tracked entities. This can help to ensure that your cached data remains consistent and up-to-date.
  - Stateless web APIs: In stateless web APIs, you may not need to track changes to entities returned by queries. In such cases, using QueryTrackingBehavior.NoTracking can reduce the amount of memory used by the context and improve performance.
    - A `stateless` web API is an application programming interface (API) that does not store client state between requests. In other words, each request to the API contains all the information necessary to complete the request, and the server does not maintain any state information between requests. This means that each request is treated as an independent transaction, and the API does not rely on session state or other server-side resources to process the request.
  - Batch updates: If you are performing batch updates to a large number of entities, using QueryTrackingBehavior.NoTracking can be more efficient than tracking the entities. This can reduce the amount of memory required by the context and improve performance.
  - Complex queries: If you are executing complex queries that join multiple tables or use subqueries, using QueryTrackingBehavior.NoTracking can improve query performance by reducing the amount of work required to track the entities.

On the other hand, you might want to use the `default tracking behavior` (which is Tracking) when:

  - You need to modify entities returned by a query and persist the changes to the database.
  - You need to access related entities that are not included in the original query. Tracked entities can be lazy-loaded, which means related entities can be loaded on demand when accessed.
  - You are working in a connected scenario (such as a desktop application) where the context is long-lived and you need to track changes to entities across multiple requests or user interactions.
  - consider `an e-commerce application where users can place orders for products.` When a user submits an order, the application needs to retrieve the product from the database, update its inventory, and save the order to the database. In this scenario, default tracking behavior is useful because it allows the application to retrieve the product from the database, update its properties (such as the inventory), and then save those changes back to the database.
  - Another scenario where default tracking behavior is useful is when you need to `perform complex data queries that require multiple database roundtrips`. In this scenario, you can use default tracking behavior to retrieve the data from the database, modify it in memory, and `then save the changes back to the database in a single transaction.`
  - In general, `default tracking behavior is most useful when you need to maintain a persistent state of your data and perform operations that require multiple database roundtrips`. However, it is important to keep in mind that default tracking behavior can have performance implications and may not be suitable for all scenarios, particularly those involving large data sets. In those cases, you may want to consider using QueryTrackingBehavior.NoTracking instead.

# what is a large data set?
he definition of a "large data set" can vary depending on the context, but generally it refers to a data set that is large enough to potentially cause performance or memory issues if not handled properly.

In the context of EF Core, a large data set might be one that contains thousands or millions of rows. If you are querying a large data set and tracking all of the entities returned by the query, this can consume a lot of memory and potentially cause performance issues. In such cases, using QueryTrackingBehavior.NoTracking can be a good option to reduce memory overhead and improve performance.

However, it's important to keep in mind that the definition of a "large data set" can depend on factors such as the available system resources, the complexity of the query, and the specific requirements of the application.
