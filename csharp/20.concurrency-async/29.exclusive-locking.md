# Exclusive Locking
There are three exclusive locking constructs: the lock statement, Mutex, and SpinLock. The lock construct is the most convenient and widely used, whereas the other two target niche scenarios:
• `Mutex` lets you span multiple processes (computer-wide locks).
• `SpinLock` implements a micro-optimization that can lessen context switches in
high-concurrency scenarios

# The lock Statement
To illustrate the need for locking, consider the following class:
    class ThreadUnsafe
    {
static int _val1 = 1, _val2 = 1;
      static void Go()
      {
        if (_val2 != 0) Console.WriteLine (_val1 / _val2);
_val2 = 0; }
}
This class is not thread-safe: if Go were called by two threads simultaneously, it would be possible to get a division-by-zero error because _val2 could be set to zero in one thread right as the other thread was in between executing the if statement and Console.WriteLine. Here’s how lock fixes the problem:
    class ThreadSafe
    {
static readonly object _locker = new object(); static int _val1 = 1, _val2 = 1;
static void Go() {
        lock (_locker)
        {
          if (_val2 != 0) Console.WriteLine (_val1 / _val2);
          _val2 = 0;
} }
}
Only one thread can lock the synchronizing object (in this case, _locker) at a time, and any contending threads are blocked until the lock is released. If more than one thread contends the lock, they are queued on a “ready queue” and granted the lock on a first-come, first-served basis.1 Exclusive locks are sometimes said to enforce serialized access to whatever’s protected by the lock because one thread’s access cannot overlap with that of another. In this case, we’re protecting the logic inside the Go method as well as the fields _val1 and _val2.

# Monitor.Enter and Monitor.Exit
C#’s lock statement is in fact a syntactic shortcut for a call to the methods Moni tor.Enter and Monitor.Exit, with a try/finally block. Here’s (a simplified ver‐ sion of ) what’s actually happening within the Go method of the preceding example:
 Monitor.Enter (_locker);
try {
      if (_val2 != 0) Console.WriteLine (_val1 / _val2);
_val2 = 0; }
finally { Monitor.Exit (_locker); }
Calling Monitor.Exit without first calling Monitor.Enter on the same object
throws an exception.

# The lockTaken overloads
The code that we just demonstrated has a subtle vulnerability. Consider the (unlikely) event of an exception being thrown between the call to Monitor.Enter and the try block (due, perhaps, to an OutOfMemoryException or, in .NET Frame‐ work, if the thread is aborted). In such a scenario, the lock might or might not be taken. If the lock is taken, it won’t be released—because we’ll never enter the try/finally block. This will result in a leaked lock. To avoid this danger, Monitor.Enter defines the following overload:
public static void Enter (object obj, ref bool lockTaken);
lockTaken is false after this method if (and only if) the Enter method throws an
exception and the lock was not taken.
Here’s the more robust pattern of use (which is exactly how C# translates a lock statement):
```c#
    bool lockTaken = false;
try {
Monitor.Enter (_locker, ref lockTaken);
      // Do your stuff...
    }
finally { if (lockTaken) Monitor.Exit (_locker); }
```

This passage explains the potential vulnerability of using Monitor.Enter without handling exceptions properly. When a thread enters a Monitor, it needs to release the lock before exiting to allow other threads to acquire the lock. However, if an exception is thrown after acquiring the lock, the lock might not be released properly, resulting in a "leaked" lock that prevents other threads from acquiring the lock and potentially causing deadlocks.

To avoid this issue, Monitor.Enter provides an overload that takes a ref bool lockTaken parameter, which indicates whether the lock was taken successfully. By passing false to this parameter initially, the caller can determine whether the lock was taken after the Monitor.Enter method returns. If an exception is thrown and the lock was not taken, the lockTaken parameter remains false, indicating that the lock was not taken and there is no need to release it.

The passage also provides a more robust pattern for using Monitor.Enter and Monitor.Exit with exception handling using a try-finally block. The `lockTaken` variable is used to keep track of whether the lock was taken successfully, and if so, to ensure that it is released properly in the finally block. This pattern is also used by the lock statement in C#.

# TryEnter
Monitor also provides a TryEnter method that allows a timeout to be specified, either in milliseconds or as a TimeSpan. The method then returns true if a lock was obtained, or false if no lock was obtained because the method timed out. TryEnter can also be called with no argument, which “tests” the lock, timing out immediately if the lock can’t be obtained immediately. As with the Enter method, TryEnter is overloaded to accept a lockTaken argument.

# Nested Locking
A thread can repeatedly lock the same object in a nested (reentrant) fashion:
    lock (locker)
      lock (locker)
        lock (locker)
        {
           // Do something...
        }
Alternatively:
Monitor.Enter (locker); Monitor.Enter (locker); Monitor.Enter (locker); // Do something...
Monitor.Exit (locker); Monitor.Exit (locker); Monitor.Exit (locker);
In these scenarios, the object is unlocked only when the outermost lock statement has exited—or a matching number of Monitor.Exit statements have executed.
Nested locking is useful when one method calls another from within a lock:
object locker = new object();
    lock (locker)
    {
      AnotherMethod();
      // We still have the lock - because locks are reentrant.
}
    void AnotherMethod()
    {
lock (locker) { Console.WriteLine ("Another method"); } }

# Deadlocks
A deadlock happens when two threads each wait for a resource held by the other, so neither can proceed. The easiest way to illustrate this is with two locks:
object locker1 = new object();
object locker2 = new object();
new Thread (() => {
lock (locker2)
{
}
Thread.Sleep (1000);
lock (locker1);
  lock (locker1)
  {
    Thread.Sleep (1000);
    lock (locker2);
  }
}).Start();
// Deadlock
// Deadlock
You can create more elaborate deadlocking chains with three or more threads.

he CLR, in a standard hosting environment, is not like SQL Server and does not automatically detect and resolve deadlocks by terminating one of the offenders. A threading deadlock causes participating threads to block indefinitely, unless you’ve specified a locking timeout. (Under the SQL CLR integration host, however, deadlocks are automatically detected, and a [catchable] exception is thrown on one of the threads.)
Deadlocking is one of the most difficult problems in multithreading—especially when there are many interrelated objects. Fundamentally, the hard problem is that you can’t be sure what locks your caller has taken out.
So, you might lock private field a within your class x, unaware that your caller (or caller’s caller) has already locked field b within class y. Meanwhile, another thread is doing the reverse—creating a deadlock. Ironically, the problem is exacerbated by (good) object-oriented design patterns, because such patterns create call chains that are not determined until runtime.
The popular advice “lock objects in a consistent order to prevent deadlocks,” although helpful in our initial example, is difficult to apply to the scenario just described. A better strategy is to be wary of locking around calls to methods in objects that might have references back to your own object. Also, consider whether you really need to lock around calls to methods in other classes (often you do—as you’ll see in “Locking and Thread Safety” on page 874—but sometimes there are other options). Relying more on higher-level synchronization options such as