# How the GC Works
The standard CLR uses a generational mark-and-compact GC that performs automatic memory management for objects stored on the managed heap. The GC is considered to be a `tracing GC in that it doesn’t interfere with every access to an object, but rather wakes up intermittently and traces the graph of objects stored on the managed heap to determine which objects can be considered garbage and therefore collected.`

1. The GC initiates a garbage collection upon performing a memory allocation (via the new keyword), either after a certain threshold of memory has been allocated or at other times to reduce the application’s memory footprint. This process can also be initiated manually by calling System.GC.Collect.` During a garbage collection, all threads can by frozen` (more on this in the next section).

2. The `GC begins with its root object references and walks the object graph, marking all the objects it touches as reachable`. When this process is complete, all objects that have not been marked are considered unused and are subject to garbage collection.

3. `Unused objects without finalizers are immediately discarded; unused objects with finalizers are enqueued for processing on the finalizer thread after the GC is complete`. These objects then become eligible for collection in the next GC for the object’s generation (unless resurrected).

4. `The remaining “live” objects are then shifted to the start of the heap (compacted), freeing space for more objects`. This compaction serves two purposes: it prevents memory fragmentation, and it allows the GC to employ a very simple strategy when allocating new objects, which is to always allocate memory at the end of the heap. This prevents the potentially time-consuming task of maintaining a list of free memory segments.

If there is insufficient space to allocate memory for a new object after garbage collection and the OS is unable to grant further memory, an OutOfMemoryException is thrown.

`NOTE`
You can obtain information about the current state of the managed heap by calling GC.GetGCMemoryInfo(). From .NET 5, this method has been enhanced to return performance-related data.

# Optimization Techniques
The GC incorporates various optimization techniques to reduce the garbage collection time.

Generational collection
The most important optimization is that the GC is generational. This takes advantage of the fact that although many objects are allocated and discarded rapidly, certain objects are long-lived and thus don’t need to be traced during every collection.

Basically, the GC divides the managed heap into three generations.` Objects that have just been allocated are in Gen0, and objects that have survived one collection cycle are in Gen1; all other objects are in Gen2. Gen0 and Gen1 are known as ephemeral (short-lived) generations.`

The CLR keeps the `Gen0 section relatively small (with a typical size of a few hundred KB to a few MB)`. When the Gen0 section fills up, the GC instigates a Gen0 collection—which happens relatively often. The GC applies a similar memory threshold to Gen1 (which acts as a buffer to Gen2), and so` Gen1 collections are relatively quick and frequent, too`. Full collections that include Gen2, however, take much longer and so happen infrequently

https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098121945/files/assets/cn10_1202.png
https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098121945/files/assets/cn10_1202.png


To give some very rough ballpark figures, a Gen0 collection might take less than one millisecond, which is not enough to be noticed in a typical application. A full collection, however, might take as long as 100 ms on a program with large object graphs. These figures depend on numerous factors and so can vary considerably—particularly in the case of Gen2, whose size is unbounded (unlike Gen0 and Gen1).

The upshot is that short-lived objects are very efficient in their use of the GC. The StringBuilders created in the following method would almost certainly be collected in a fast Gen0:

string Foo()
{
  var sb1 = new StringBuilder ("test");
  sb1.Append ("...");
  var sb2 = new StringBuilder ("test");
  sb2.Append (sb1.ToString());
  return sb2.ToString();
}

# The Large Object Heap
The `GC uses a separate heap called the Large Object Heap (LOH) for objects larger than a certain threshold (currently 85,000 bytes)`. This prevents the cost of compacting large objects and prevents excessive Gen0 collections—without the LOH, allocating a series of 16 MB objects might trigger a Gen0 collection after every allocation.

By default, the LOH is not subject to compaction, because moving large blocks of memory during garbage collection would be prohibitively expensive. This has two consequences:
  - Allocations can be slower, because the GC can’t always simply allocate objects at the end of the heap—it must also look in the middle for gaps, and this requires maintaining a linked list of free memory blocks.1
  - The LOH is subject to fragmentation. This means that the freeing of an object can create a hole in the LOH that can be difficult to fill later. For instance, a hole left by an 86,000-byte object can be filled only by an object of between 85,000 bytes and 86,000 bytes (unless adjoined by another hole).

Should you anticipate a problem with fragmentation, you can instruct the GC to compact the LOH in the next collection, as follows:

GCSettings.LargeObjectHeapCompactionMode =
  GCLargeObjectHeapCompactionMode.CompactOnce;
Another workaround, if your program frequently allocates large arrays, is to use .NET’s array pooling API (see “Array Pooling”).

The LOH is also nongenerational: all objects are treated as Gen2.

# Workstation versus server collection
.NET provides two garbage collection modes: workstation and server. Workstation is the default; you can switch to server by adding the following to your application’s .csproj file:

<PropertyGroup>
  <ServerGarbageCollection>true</ServerGarbageCollection>
</PropertyGroup>
Upon building your project, this setting is written to the application’s .runtime​con⁠fig.json file, where’s it’s read by the CLR:

  "runtimeOptions": {
    "configProperties": {
      "System.GC.Server": true
    ...
When server collection is enabled, the CLR allocates a separate heap and GC to each core. This speeds up collection but consumes additional memory and CPU resources (because each core requires its own thread). Should the machine be running many other processes with server collection enabled, this can lead to CPU oversubscription, which is particularly harmful on workstations because it makes the OS as a whole feel unresponsive.

Server collection is available only on multicore systems: on single-core devices (or single-core virtual machines), the setting is ignored.



In the .NET framework, the garbage collector is responsible for reclaiming memory that is no longer being used by an application. The garbage collector runs periodically and identifies objects that are no longer being used and frees up the memory used by those objects.

The .NET framework provides two types of garbage collectors: Workstation garbage collector and Server garbage collector.

The workstation garbage collector is optimized for single-processor machines and is the default garbage collector for client applications. It's designed to minimize pauses in the application by using a technique called concurrent garbage collection. In this technique, the garbage collector runs concurrently with the application, freeing up memory in small chunks while the application is running.

The server garbage collector, on the other hand, is optimized for multiprocessor machines and is designed to handle larger and more complex applications. It uses a technique called server garbage collection, which divides the heap into multiple sections and assigns each section to a different processor. The garbage collector then runs in parallel on each section, freeing up memory in larger chunks.

In general, the server garbage collector is more suitable for server applications that require high throughput and low latency. This is because it can use multiple processors to perform garbage collection, which reduces the time spent on garbage collection and improves the overall performance of the application.

However, the workstation garbage collector is more suitable for client applications that require fast response times and low memory usage. This is because the concurrent garbage collection technique used by the workstation garbage collector reduces the amount of time spent on garbage collection, which helps to minimize pauses in the application.

It's worth noting that the choice between the workstation and server garbage collector can be influenced by a number of factors, such as the size and complexity of the application, the number of processors available, and the desired performance characteristics. As such, it's important to test both garbage collectors and choose the one that provides the best performance for your specific application.

# Background collection
In both workstation and server modes, the CLR enables background collection by default. You can disable it by adding the following to your application’s .csproj file:

<PropertyGroup>
  <ConcurrentGarbageCollection>false</ConcurrentGarbageCollection>
</PropertyGroup>
Upon building, this setting is written to the application’s .runtimeconfig.json file:

  "runtimeOptions": {
    "configProperties": {
      "System.GC.Concurrent": false,
   ...
The GC must freeze (block) your execution threads for periods during a collection. Background collection minimizes these periods of latency, making your application more responsive. This comes at the expense of consuming slightly more CPU and memory. Hence, by disabling background collection, you accomplish the following:

Slightly reduce CPU and memory usage

Increase the pauses (or latency) when a garbage collection occurs

Background collection works by allowing your application code to run in parallel with a Gen2 collection. (Gen0 and Gen1 collections are considered sufficiently fast that they don’t benefit from this parallelism.)

Background collection is an improved version of what was formerly called concurrent collection: it removes a limitation whereby a concurrent collection would cease to be concurrent if the Gen0 section filled up while a Gen2 collection was running. This allows applications that continually allocate memory to be more responsive.

# GC notifications
If you disable background collection, you can ask the GC to notify you just before a full (blocking) collection will occur. This is intended for server-farm configurations: the idea is that you divert requests to another server just before a collection. You then instigate the collection immediately and wait for it to complete before rerouting requests back to that server.

To start notification, call GC.RegisterForFullGCNotification. Then, start up another thread (see Chapter 14) that first calls GC.WaitForFullGCApproach. When this method returns a GCNotificationStatus indicating that a collection is near, you can reroute requests to other servers and force a manual collection (see the following section). You then call GC.WaitForFullGCComplete: when this method returns, collection is complete, and you can again accept requests. You then repeat the whole cycle.

# Forcing Garbage Collection
You can manually force a garbage collection at any time by calling` GC.Collect`. Calling GC.Collect without an argument instigates a full collection. If you pass in an integer value, only generations to that value are collected, so `GC.Collect(0)` performs only a fast Gen0 collection.


In general, you get the best performance by allowing the GC to decide when to collect: forcing collection can hurt performance by unnecessarily promoting Gen0 objects to Gen1 (and Gen1 objects to Gen2). It can also upset the GC’s self-tuning ability, whereby the GC dynamically tweaks the thresholds for each generation to maximize performance as the application executes.

There are exceptions, however. The most common case for intervention is when an application goes to sleep for a while: a good example is a Windows Service that performs a daily activity (checking for updates, perhaps). Such an application might use a System.Timers.Timer to initiate the activity every 24 hours. After completing the activity, no further code executes for 24 hours, which means that for this period, no memory allocations are made and so the GC has no opportunity to activate. Whatever memory the service consumed in performing its activity, it will continue to consume for the following 24 hours—even with an empty object graph! The solution is to call GC.Collect right after the daily activity completes.

To ensure the collection of objects for which collection is delayed by finalizers, take the additional step of calling WaitForPendingFinalizers and re-collecting:
```c#
GC.Collect();
GC.WaitForPendingFinalizers();
GC.Collect();
```
Often this is done in a loop: the act of running finalizers can free up more objects that themselves have finalizers.

Another case for calling GC.Collect is when you’re testing a class that has a finalizer.

The first line, GC.Collect(), is a call to the Collect method of the GC (Garbage Collector) class. This method forces a garbage collection cycle to occur, which means that the garbage collector will run immediately and attempt to free up memory that is no longer being used by the application.

The second line, GC.WaitForPendingFinalizers(), is a call to the WaitForPendingFinalizers method of the GC class. This method blocks the current thread until all finalizers have been executed for objects that have been marked for finalization. Finalizers are special methods that are executed when an object is garbage collected, and they are used to release unmanaged resources such as file handles or network connections.

The third line, GC.Collect(), is another call to the Collect method of the GC class. This second call to Collect is used to ensure that all objects that were marked for finalization have been collected and their memory has been freed up.

It's worth noting that forcing garbage collection and finalization in this way can have a negative impact on performance and should generally be avoided unless there is a specific need to do so. In most cases, the garbage collector will run automatically when needed and finalizers will be executed in a timely manner.

# Tuning Garbage Collection at Runtime
The static GCSettings.LatencyMode property determines how the GC balances latency with overall efficiency. Changing this from its default value of Interactive to either LowLatency or SustainedLowLatency instructs the CLR to favor quicker (but more frequent) collections. This is useful if your application needs to respond very quickly to real-time events. Changing the mode to Batch maximizes throughput at the expense of potentially poor responsiveness, which is useful for batch processing.

SustainedLowLatency is not supported if you disable background collection in the .runtimeconfig.json file.

You can also tell the CLR to temporarily suspend garbage collection by calling GC.TryStartNoGCRegion, and resume it with GC.EndNoGCRegion.

# Memory Pressure
The runtime decides when to initiate collections based on a number of factors, including the total memory load on the machine. If your program allocates unmanaged memory (Chapter 24), the runtime will get an unrealistically optimistic perception of its memory usage because the CLR knows only about managed memory. You can mitigate this by instructing the CLR to assume that a specified quantity of unmanaged memory has been allocated; you do this by calling GC.AddMemory​Pres⁠sure. To undo this (when the unmanaged memory is released), call GC.Remove​Memor⁠yPressure.

# Array Pooling
If your application frequently instantiates arrays, you can avoid most of the garbage collection overhead with array pooling. Array pooling was introduced in .NET Core 3 and works by “renting” an array, which you later return to a pool for reuse.

To allocate an array, call the Rent method on the ArrayPool class in the System​.Buf⁠fers namespace, indicating the size of the array that you’d like:

int[] pooledArray = ArrayPool<int>.Shared.Rent (100);  // 100 bytes
This allocates an array of (at least) 100 bytes from the global shared array pool. The pool manager might give you an array that’s larger than what you asked for (typically, it allocates in powers of 2).

When you’ve finished with the array, call Return: this releases the array to the pool, allowing the same array to be rented again:

ArrayPool<int>.Shared.Return (pooledArray);
You can optionally pass in a Boolean value instructing the pool manager to clear the array before returning it to the pool.

WARNING
A limitation of array pooling is that nothing prevents you from continuing to (illegally) use an array after it’s been returned, so you need to code carefully to avoid this scenario. Keep in mind that you have the power to break not just your own code but other APIs that use array pooling, too, such as ASP.NET Core.

Rather than using the shared array pool, you can create a custom pool and rent from that. This prevents the risk of breaking other APIs, but increases overall memory usage (as it reduces the opportunities for reuse):

var myPool = ArrayPool<int>.Create();
int[] array = myPool.Rent (100);
...

