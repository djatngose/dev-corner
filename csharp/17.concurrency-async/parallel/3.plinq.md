# PLINQ
`PLINQ` automatically parallelizes local LINQ queries. `PLINQ` has the advantage of being easy to use in that it offloads the burden of both work partitioning and result collation to .NET.

To use `PLINQ`, simply call `AsParallel()` on the input sequence and then con‐ tinue the LINQ query as usual. The following query calculates the prime numbers between 3 and 100,000, making full use of all cores on the target machine:

```c#
// Calculate prime numbers using a simple (unoptimized) algorithm.
IEnumerable<int> numbers = Enumerable.Range (3, 100000-3);
var parallelQuery =
from n in numbers.AsParallel()
where Enumerable.Range (2, (int) Math.Sqrt (n)).All (i => n % i > 0) select n;
    int[] primes = parallelQuery.ToArray();
```
`AsParallel` is an extension method in System.Linq.ParallelEnumerable. It wraps the input in a sequence based on `ParallelQuery<TSource>`, which causes the LINQ query operators that you subsequently call to bind to an alternate set of extension methods defined in ParallelEnumerable.

These provide parallel implementations of each of the standard query operators. Essentially, they work by `partitioning the input sequence into chunks that execute on different threads`, collating the results back into a single output sequence for consumption,

```c#
abcdef .AsParallel() => thread 1(a,b), thread 2(c,d), thread 3(e,f) 
```
Calling `AsSequential()` unwraps a ParallelQuery sequence so that subsequent query operators `bind to the standard query operators and execute sequentially`. This is necessary before calling methods that have side effects or are not thread-safe. That means Once you call `AsSequential()`, the `query will not be processed in parallel anymore`. It essentially "resets" the query to a sequential processing mode, where subsequent operators will be executed in the order they were written in the query.

`AsParallel()` may be faster than the `AsParallel().AsSequential()` if the query is computationally intensive and the overhead of switching between parallel and sequential modes is significant.

# Join, GroupJoin, Concat, Union, Intersect, Except, and Zip
For query operators that accept two input sequences `(Join, GroupJoin, Concat, Union, Intersect, Except, and Zip)`, you must apply A`sParallel() `to both input sequences (otherwise, an exception is thrown).

```c#
IEnumerable<int> sequence1 = Enumerable.Range(0, 10000).AsParallel();
IEnumerable<int> sequence2 = Enumerable.Range(5000, 10000).AsParallel();

var result = sequence1.Union(sequence2).ToList();

```
In this example, both sequence1 and sequence2 are parallelized using AsParallel(). When the Union operator is called on the two sequences, PLINQ ensures that both sequences are merged and partitioned across multiple threads to perform the union operation in parallel.

It's important to note that we only need to apply `AsParallel() `to the input sequences once. In other words, we don't need to keep calling AsParallel() on the query as it progresses. Doing so can introduce inefficiency as it forces merging and repartitioning of the query.
  -  In this case, you don't need to call `AsParallel()` because `Union` is a query operator that already returns a ParallelQuery sequence, which means that the subsequent operations will be processed in parallel.

You don’t, however, need to keep applying `AsParallel` to a query as it progresses, because PLINQ’s query operators output another ParallelQuery sequence. 
In fact, calling AsParallel again introdues inefficiency in that it forces merging and repartitioning of the query:

```c#
mySequence.AsParallel()
          .Where (n => n > 100)
          .AsParallel()
          .Select (n => n * n)
// Wraps sequence in ParallelQuery<int> // Outputs another ParallelQuery<int> // Unnecessary - and inefficient!
```
Not all query operators can be effectively parallelized. For those that cannot (see “PLINQ Limitations” on page 914), PLINQ implements the operator sequentially, instead. `PLINQ might also operate sequentially if it suspects that the overhead of parallelization will actually slow a particular query.`

`PLINQ is only for local collections: it doesn’t work with Entity Framework,` for instance, because in those cases the LINQ translates into SQL, which then executes on a database server. However, you can use PLINQ to perform additional local querying on the result sets obtained from database queries.

`Note`: If a PLINQ query throws an exception, it’s rethrown as an AggregateException whose InnerExceptions property con‐ tains the real exception (or exceptions)

# Parallel Execution Logic Flow
Like ordinary `LINQ` queries, `PLINQ queries are lazily evaluated`. This means that execution is` triggered only when you begin consuming the results—typically via a foreach loop `(although it can also be via a conversion operator such as ToArray or an operator that returns a single element or value).

In a `sequential query`, the consumer pulls the data from the input sequence as it is required, meaning that each element is fetched one at a time in the order that they are needed

On the other hand, in a `parallel query`,
  - Independent threads are used to fetch elements from the input sequence slightly ahead of when they are needed by the consumer. This is done in order to process the elements in parallel and improve performance.
  -  The results are held in a small buffer so that they are ready for the consumer on demand. `If the consumer pauses or breaks out of the enumeration early, the query processor also pauses or stops in order to avoid wasting CPU time or memory.`

Suppose you have a large sequence of numbers, and you want to filter out only the even numbers, then square them, and finally sum them up. Here's how a sequential query would work:
```c#
var numbers = Enumerable.Range(1, 1000000); // a sequence of 1 million numbers
var result = numbers
    .Where(n => n % 2 == 0) // filter out only the even numbers
    .Select(n => n * n) // square each even number
    .Sum(); // sum up all the squares

```
With a `sequential query`, the consumer (the Sum() operator) fetches each number from the input sequence (the Where() and Select() operators) one at a time, and only when it needs them. For example, when it needs to calculate the sum, it fetches the first even number, squares it, adds it to the running total, then fetches the next even number, and so on.

Now, let's consider how a `parallel query` would work. PLINQ would use multiple threads to fetch the input numbers slightly ahead of when they're needed by the consumer. For example, while the consumer is adding up the squares of the first few even numbers, the PLINQ query would be fetching the next few even numbers in parallel, so that they're ready to be squared and added to the running total as soon as the consumer needs them. This can potentially make the query faster, especially if the input sequence is very large and the processing of each element takes a non-trivial amount of time.

However, if the consumer `pauses or breaks out of the enumeration early` (for example, if it reaches a certain threshold), the PLINQ query processor will also pause or stop the parallel processing of the remaining elements, so as not to waste CPU time or memory. This is because the input sequence is being fetched ahead of when it's actually needed, and there's no point in fetching more elements than necessary.

## Prefetching
`Prefetching` is a technique used by PLINQ to improve performance by fetching data ahead of time. PLINQ uses multiple threads to prefetch the input data slightly ahead of when it is needed by the consumer. This reduces the time spent waiting for data to be fetched and improves the overall performance of the query.

The specific implementation of `prefetching` in PLINQ is complex and involves a number of different techniques and algorithms, such as dynamic partitioning and load balancing, to ensure that the data is fetched efficiently and that the workload is distributed evenly across the available threads. The goal of `prefetching` is to ensure that the query can be processed as quickly and efficiently as possible, without unnecessary delays or bottlenecks.

`Note`: You can tweak PLINQ’s buffering behavior by calling With `MergeOptions` after `AsParallel`. The default value of AutoBuf fered generally gives the best overall results. `NotBuffered` disables the buffer and is useful if you want to see results as soon as possible; `FullyBuffered` caches the entire result set before presenting it to the consumer (the OrderBy and Reverse operators naturally work this way, as do the element, aggregation, and conversion operators).

# Why Isn’t AsParallel the Default?
Given that AsParallel transparently parallelizes LINQ queries, the question arises: why didn’t Microsoft simply parallelize the standard query operators and make PLINQ the default?

There are a number of reasons for the opt-in approach. First, for PLINQ to be useful there must be a reasonable amount of computationally intensive work for it to farm out to worker threads. Most LINQ-to-Objects queries execute very quickly; thus, not only would parallelization be unnecessary, but the overhead of partitioning, collating, and coordinating the extra threads might actually slow things down.

`Additionally`:
• The output of a PLINQ query (by default) can differ from a LINQ query with
respect to element ordering (see “PLINQ and Ordering” on page 913).
• PLINQ wraps exceptions in an `AggregateException` (to handle the possibility
of multiple exceptions being thrown).
• PLINQ will give `unreliable results if the query invokes thread-unsafe methods`.

Finally, PLINQ offers quite a few hooks for tuning and tweaking. Burdening the standard LINQ-to-Objects API with such nuances would add distraction.

# Ordering
A side effect of parallelizing the query operators is that when the results are collated, it’s not necessarily in the same order that they were submitted (see Figure 22-2). In other words, LINQ’s normal order-preservation guarantee for sequences no longer holds.

`Note`:  `"collated"` in this context means the process of combining the parallel query operator results into a final sequence, which may not be in the same order as the input sequence.

If you need order preservation, you can force it by calling AsOrdered() after AsParallel():
```c#
myCollection.AsParallel().AsOrdered()...
```

Calling `AsOrdered` incurs a p`erformance hit with large numbers of elements because PLINQ must keep track of each element’s original position.`


You can` negate the effect of AsOrdered `later in a query by calling `AsUnordered`: this introduces a “random shuffle point,” which allows the query to execute more efficiently from that point on. So, if you wanted to preserve input-sequence ordering for just the first two query operators, you’d do this:
```c#
inputSequence.AsParallel().AsOrdered()
.QueryOperator1()
.QueryOperator2()
.AsUnordered() // From here on, ordering doesn’t matter
.QueryOperator3()
...
```

`AsOrdered is not the default `because for most queries, the original input ordering doesn’t matter. In other words, if AsOrdered were the default, you’d need to apply AsUnordered to the majority of your parallel queries to get the best performance, which would be burdensome.

# Limitations
There are practical limitations on what PLINQ can parallelize. The following query operators prevent parallelization by default u. This is because m`ost query operators change the indexing position of elements` unless the source elements are in their original indexing position
  - The indexed versions of `Select, SelectMany, and ElementAt`


Most query operators change the indexing position of elements (including those that remove elements, such as Where). 
This means that if you want to use the preceding operators, they’ll usually need to be at the start of the query.
The following `query operators are parallelizable but use an expensive partitioning strategy that can sometimes be slower than sequential processing`:
  - `Join, GroupBy, GroupJoin, Distinct, Union, Intersect, and Except`

The `Aggregate` operator’s seeded overloads in their standard incarnations are not parallelizable—PLINQ provides special overloads to deal with this (see “Optimizing PLINQ” on page 919).
All other operators are parallelizable, although use of these operators doesn’t guar‐ antee that your query will be parallelized. PLINQ might run your query sequentially if it suspects that the overhead of parallelization will slow down that particular query. You can override this behavior and force parallelism by calling the following after AsParallel():
```c#
    .WithExecutionMode (ParallelExecutionMode.ForceParallelism)
```
# Example: Parallel Spellchecker
Suppose that we want to write a spellchecker that runs quickly with very large documents by utilizing all available cores. By formulating our algorithm into a LINQ query, we can very easily parallelize it.

The first step is to download a dictionary of English words into a HashSet for efficient lookup:
```c#
 if (!File.Exists ("WordLookup.txt")    // Contains about 150,000 words
      File.WriteAllText ("WordLookup.txt",
        await new HttpClient().GetStringAsync (
          "http://www.albahari.com/ispell/allwords.txt"));
    var wordLookup = new HashSet<string> (
      File.ReadAllLines ("WordLookup.txt"),
      StringComparer.InvariantCultureIgnoreCase);

```

We then use our word lookup to create a test “document” comprising an array of a million random words. After we build the array, let’s introduce a couple of spelling mistakes:

```c#
 var random = new Random();
    string[] wordList = wordLookup.ToArray();
    string[] wordsToTest = Enumerable.Range (0, 1000000)
      .Select (i => wordList [random.Next (0, wordList.Length)])
      .ToArray();
    wordsToTest [12345] = "woozsh";     // Introduce a couple
    wordsToTest [23456] = "wubsie";     // of spelling mistakes.
```

Now we can perform our parallel spellcheck by testing wordsToTest against wordLookup. PLINQ makes this very easy:

```c#
 var query = wordsToTest
.AsParallel()
.Select ((word, index) => new IndexedWord { Word=word, Index=index }) .Where (iword => !wordLookup.Contains (iword.Word))
.OrderBy (iword => iword.Index);

foreach (var mistake in query)
      Console.WriteLine (mistake.Word + " - index = " + mistake.Index);
    // OUTPUT:
    // woozsh - index = 12345
    // wubsie - index = 23456
struct IndexedWord { public string Word; public int Index; }
```

## Using ThreadLocal<T>

Let’s extend our example by parallelizing the creation of the random test-word list itself. We structured this as a LINQ query, so it should be easy. Here’s the sequential version:
```c#
string[] wordsToTest = Enumerable.Range (0, 1000000) 
                      .Select (i => wordList [random.Next (0, wordList.Length)]) .ToArray();
```

`Unfortunately`, the call to `random.Next is not thread-safe`, 
  - why random.Next is not thread-safe? because its internal state is modified every time the Next method is called. If multiple threads call the Next method on the same instance of System.Random concurrently, they can cause race conditions and corrupt the internal state of the random number generator, leading to unexpected or incorrect results.
```c#
using System;
using System.Threading.Tasks;

class Program
{
    static void Main()
    {
        var random = new Random();

        // Parallel loop that uses Random.Next
        Parallel.For(0, 10, i =>
        {
            Console.WriteLine($"Thread {Task.CurrentId} generated random number {random.Next()}");
        });
    }
}
//OUTPUT
Thread 4 generated random number 2132344994
Thread 4 generated random number 1747847398
Thread 4 generated random number 527190854
Thread 4 generated random number 1021796613
Thread 3 generated random number 2132344994
Thread 2 generated random number 1747847398
Thread 5 generated random number 527190854
Thread 1 generated random number 1021796613
Thread 3 generated random number 713270424
Thread 5 generated random number 313870254

```
In this example, we create a Random instance outside the parallel loop and use it inside the loop to generate random numbers. However, since Random.Next is not thread-safe, multiple threads can access the same instance of Random at the same time and cause unexpected results.

so it’s not as simple as inserting `AsParallel()` into the query. A potential solution is to write a function that locks around random.Next; however, this would limit concurrency. The better option is to use `ThreadLocal<Random>` (see “Thread-Local Storage” on page 898) to `create a separate Random object for each thread`. We then can parallelize the query, as follows:
```c#
var localRandom = new ThreadLocal<Random>( () => new Random (Guid.NewGuid().GetHashCode()) );
string[] wordsToTest = Enumerable.Range (0, 1000000).AsParallel() 
                    .Select (i => wordList [localRandom.Value.Next (0, wordList.Length)]) .ToArray();
```
In our factory function for instantiating a Random object, `we pass in a Guid’s hash‐ code to ensure that if two Random objects are created within a short period of time, they’ll yield different random number sequences`.

# When to Use PLINQ
It’s tempting to search your existing applications for LINQ queries and experiment with parallelizing them. This is usually unproductive, because most problems for which LINQ is obviously the best solution tend to execute very quickly and so don’t benefit from parallelization. A `better approach is to find a CPU-intensive bottleneck and then consider whether it can be expressed as a LINQ query`. (A welcome side effect of such restructuring is that LINQ typically makes code smaller and more readable.)

PLINQ is well suited to embarrassingly parallel problems. It can be a `poor choice for imaging, however, because collating millions of pixels into an output sequence creates a bottleneck`. Instead, it’s better to write pixels directly to an array or unman‐ aged memory block and use the Parallel class or task parallelism to manage the multithreading. (It is possible, however, to defeat result collation using ForAll—we discuss this in “Optimizing PLINQ” on page 919. Doing so makes sense if the image-processing algorithm naturally lends itself to LINQ.)

# Functional Purity caevats
Because PLINQ runs your query on parallel threads, `you must be careful not to perform thread-unsafe operations. In particular`, writing to variables is side-effecting and therefore thread-unsafe:

```c#
// The following query multiplies each element by its position.
// Given an input of Enumerable.Range(0,999), it should output squares.
int i = 0;
var query = from n in Enumerable.Range(0,999).AsParallel() select n * i++;
```

`We could make incrementing i thread-safe by using locks`, but the problem would still remain that i won’t necessarily correspond to the position of the input element. And adding AsOrdered to the query wouldn’t fix the latter problem, because AsOr dered ensures only that the elements are output in an order consistent with them having been processed sequentially—it doesn’t actually process them sequentially.
  - Using a lock would make the increment of i thread-safe, but it would not guarantee the expected result. The reason is that AsParallel() partitions the input sequence and processes each partition independently and concurrently. Therefore, each partition will have its own instance of i that is incremented independently of other partitions.
  - Using a lock would serialize the access to i, but it would not prevent different threads from accessing different instances of i. Hence, the result of the query would depend on the order in which the partitions are processed and the order in which the lock is acquired, which is not deterministic and may vary from run to run.
  - Therefore, to make the query correct, you would need to ensure that the order of processing and the value of i are consistent across all partitions, which is difficult to achieve in a parallel context.

The correct solution is to rewrite our query to use the indexed version of Select: 
```c#
var query = Enumerable.Range(0,999).AsParallel().Select ((n, i) => n * i);
```
For best performance, any methods called from query operators should be thread- safe by virtue of not writing to fields or properties (non-side-effecting, or function‐ ally pure). If they’re thread-safe by virtue of locking, the query’s parallelism potential will be limited by the duration of the lock divided by the total time spent in that function.
  - This means that to achieve the best performance in a PLINQ query, `any methods called from query operators should not modify any shared state, such as fields or properties. Instead, they should be "functionally pure" or "non-side-effecting,"` meaning that they return the same output for a given input and do not modify any external state.
  - `If a method needs to modify shared state, it can do so by using locks, but this can limit the parallelism potential of the query`. This is `because while a thread holds a lock, no other thread can access the shared state, which can cause contention and reduce the amount of parallelism that can be achieved`. The duration of the lock divided by the total time spent in the function can be used to estimate the amount of parallelism that is lost due to locking.

# Setting the Degree of Parallelism
By default, PLINQ chooses an optimum degree of parallelism for the processor in use. You can override it by calling WithDegreeOfParallelism after AsParallel:

```c#
...AsParallel().WithDegreeOfPallelism(4)...
```
An example of when you might increase the parallelism beyond the core count is with I/O-bound work (downloading many web pages at once, for instance). However, task combinators and asynchronous functions provide a similarly easy and more efficient solution (see “Task Combinators” on page 663). `Unlike with Tasks, PLINQ cannot perform I/O-bound work without blocking threads (and pooled threads, to make matters worse).`
## Changing the degree of parallelism
You can call WithDegreeOfParallelism only once within a PLINQ query. If you need to call it again, you must force merging and repartitioning of the query by calling AsParallel() again within the query:
```c#
"The Quick Brown Fox"
.AsParallel()
.WithDegreeOfParallelism (2)
.Where (c => !char.IsWhiteSpace (c))
.AsParallel().WithDegreeOfParallelism (3) // Forces Merge + Partition
.Select (c => char.ToUpper (c))
```

# Cancellation
`Canceling` a PLINQ query whose results you’re consuming in a foreach loop is easy: simply break out of the foreach, and the query will be automatically canceled as the enumerator is implicitly disposed.

For a query that terminates with a conversion, element, or aggregation operator, you can cancel it from another thread via a cancellation token (see “Cancellation” on page 659). To insert a token, call WithCancellation after calling AsParallel, pass‐ ing in the Token property of a CancellationTokenSource object. Another thread can then call Cancel on the token source, which throws an OperationCanceled Exception on the query’s consumer:

```C#
IEnumerable<int> million = Enumerable.Range (3, 1000000);
var cancelSource = new CancellationTokenSource();

var primeNumberQuery =
from n in million.AsParallel().WithCancellation (cancelSource.Token)
where Enumerable.Range (2, (int) Math.Sqrt (n)).All (i => n % i > 0) select n;

new Thread (() => {
   Thread.Sleep (100);
   cancelSource.Cancel(); // Cancel query after 100 milliseconds.
} ).Start();

try {

  // Cancel query after
  // 100 milliseconds.
  // Start query running:
  int[] primes = primeNumberQuery.ToArray();
  // We'll never get here because the other thread will cancel us.
}
catch (OperationCanceledException) {
      Console.WriteLine ("Query canceled");
 }
```
`Upon cancellation, PLINQ waits for each worker thread to finish with its current element before ending the query. This means that any external methods that the query calls will run to completion.`
  - This means that when a PLINQ query is cancelled, the cancellation doesn't happen immediately. Instead, PLINQ waits for each worker thread to complete its current task before ending the query. This is important to note because if the query is calling any external methods, those methods will continue to run to completion before the query is fully cancelled. Therefore, it's important to design external methods with cancellation support in order to avoid unnecessary work or to free up resources as soon as possible.

Let's say we have the following PLINQ query:
```c#
var query = Enumerable.Range(1, 1000000)
    .AsParallel()
    .Where(x => IsPrime(x))
    .ToList();

```
In this query, the Where method calls an external method IsPrime to check if a number is prime or not.

Now let's say we want to cancel this query after processing the first 1000 elements. We can do that using a `CancellationTokenSource` like this:
```c#
var cts = new CancellationTokenSource();
cts.CancelAfter(TimeSpan.FromSeconds(1)); // cancel after 1 second

var query = Enumerable.Range(1, 1000000)
    .AsParallel()
    .WithCancellation(cts.Token)
    .Where(x => IsPrime(x))
    .Take(1000)
    .ToList();

```
In this modified query, we added a `WithCancellation` method to pass in a CancellationToken that will cancel the query after 1 second. We also added a Take method to limit the number of results to 1000.

When the cancellation is triggered, PLINQ will wait for each worker thread to finish processing its current element before ending the query. This means that the external method `IsPrime` will continue to run until it finishes processing the current element, even though the query has been cancelled.

