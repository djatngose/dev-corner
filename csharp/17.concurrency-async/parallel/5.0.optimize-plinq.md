# Optimizing PLINQ

# Output-side optimization 
One of `PLINQ’s advantages` is that it conveniently collates the results from `parallelized` work into a single output sequence. Sometimes, though, all that you end up doing with that sequence is running some function once over each element:
```c#
foreach (int n in parallelQuery)
  DoSomething (n);
```
If this is the case—and you don’t care about the order in which the elements are processed—you can improve efficiency with `PLINQ’s ForAll` method.

The `ForAll` method runs a delegate over every output element of a ParallelQuery. It hooks directly into PLINQ’s internals, bypassing the steps of collating and enu‐ merating the results. Here’s a trivial example:
```c#
    "abcdef".AsParallel().Select (c => char.ToUpper(c)).ForAll (Console.Write);
```
`Note`: Collating and enumerating results is not a massively expen‐ sive operation, so the ForAll optimization yields the greatest gains when there are large numbers of quickly executing input elements.

In `PLINQ`, when you execute a query, the results are collated and returned as a single output sequence. However, sometimes you might just want to perform some action on each element without actually needing the collated output sequence. In such cases, you can use the ForAll method instead of the foreach loop to process each element more efficiently.

The `ForAll` method applies a delegate to each element of a ParallelQuery without waiting for the query to complete and the elements to be collated. It directly hooks into the internal pipeline of PLINQ and processes the elements as soon as they are produced by the parallel operations. This allows for more efficient use of resources and better performance, especially for large datasets.

Let's say we have a large collection of numbers and we want to perform some computation on each number in parallel. We can use PLINQ to parallelize the computation and ForAll method to improve the performance. Here's an example:
```c#
using System;
using System.Linq;

class Program
{
    static void Main(string[] args)
    {
        int[] numbers = Enumerable.Range(1, 10000000).ToArray();

        // Parallel computation using PLINQ and ForAll
        numbers.AsParallel().ForAll(x => Compute(x));

        // Sequential computation using foreach loop
        foreach (var number in numbers)
        {
            Compute(number);
        }
    }

    static void Compute(int n)
    {
        // some computation here
        double result = Math.Sqrt(n) * Math.Sin(n) / Math.Cos(n);

        Console.WriteLine($"Computed for {n} and result is {result}");
    }
}

```
In the above example, we have an array of 10 million numbers and we want to compute some function on each number. We have two methods of doing this: using PLINQ and ForAll method or using a foreach loop.

When we run the program, we can see that the PLINQ and ForAll method takes less time to execute compared to the foreach loop:
```c#
// Output using PLINQ and ForAll
Computed for 1 and result is -0.106631361445415
Computed for 5 and result is 2.99311858372766
Computed for 2 and result is -0.416146836547142
Computed for 6 and result is -0.0114568403251863
Computed for 4 and result is -0.654412712428603
Computed for 3 and result is 0.260596870002592
...

Time taken using PLINQ and ForAll: 00:00:00.5066005

// Output using foreach loop
Computed for 1 and result is -0.106631361445415
Computed for 2 and result is -0.416146836547142
Computed for 3 and result is 0.260596870002592
Computed for 4 and result is -0.654412712428603
Computed for 5 and result is 2.99311858372766
Computed for 6 and result is -0.0114568403251863
...

Time taken using foreach loop: 00:00:01.8612511

```
As we can see, the PLINQ and ForAll method took around 0.5 seconds to execute while the foreach loop took around 1.8 seconds to execute. This is because PLINQ parallelizes the computation, while the foreach loop executes the computation sequentially.

# Input-side optimization
`PLINQ` has `three partitioning strategies for assigning input elements to threads`:
```                           Element allocation             Relative performance
  - Chunk paritioning:              Dyanmic                       Average
  - Range paritioning:              Static                    Poor to excellent
  - Hash paritioning:               Static                        Poor
```

For query operators that require comparing elements `(GroupBy, Join, GroupJoin, Intersect, Except, Union, and Distinct)`, you have no choice: PLINQ always uses `hash partitioning`.

`Hash partitioning` is relatively inefficient in that it must `precalculate the hashcode of every element` (so that elements with identical hashcodes can be processed on the same thread). If you find this to be too slow, your only option is to call `AsSequential` to disable parallelization.

For all other query operators, you have a choice as to whether to use range or chunk partitioning. By default:
  - If the input sequence is `indexable` (if it’s an array or implements IList<T>), PLINQ chooses `range partitioning`.
  - Otherwise, PLINQ chooses `chunk partitioning`.

In a nutshell, `range partitioning is faster with long sequences for which every ele‐ ment takes a similar amount of CPU time to process. Otherwise, chunk partitioning is usually faster`

To `force range partitioning`:
• If the query starts with `Enumerable.Range`, replace that method with `ParallelEnumerable.Range`.
  - `ParallelEnumerable.Range` is not simply a shortcut for call‐ ing Enumerable.Range(...).AsParallel(). It changes the performance of the query by activating range partitioning.
• Otherwise, simply call `ToList or ToArray` on the input sequence (obviously, this incurs a performance cost in itself, which you should take into account).


To `force chunk partitioning`, wrap the input sequence in a call to `Partitioner.Create` (in System.Collection.Concurrent), as follows:
```c#
int[] numbers = { 3, 4, 5, 6, 7, 8, 9 };
var parallelQuery = Partitioner.Create (numbers, true).AsParallel() .Where (...)
```

# Optimizing custom aggregations
PLINQ parallelizes the `Sum, Average, Min, and Max `operators efficiently without additional intervention. The Aggregate operator, though, presents special challenges for PLINQ. As described in Chapter 9, Aggregate performs custom aggrega‐ tions. For example, the following sums a sequence of numbers, mimicking the Sum operator:
```c#
int[] numbers = { 1, 2, 3 };
    int sum = numbers.Aggregate (0, (total, n) => total + n);   // 6

```
We also saw in Chapter 9 that for unseeded aggregations, the supplied delegate must be associative and commutative. PLINQ will give incorrect results if this rule is violated, because it draws multiple seeds from the input sequence in order to aggregate several partitions of the sequence simultaneously.

Explicitly seeded aggregations might seem like a safe option with PLINQ, but unfortunately these ordinarily execute sequentially because of the reliance on a single seed. To mitigate this, PLINQ provides another overload of Aggregate that lets you specify multiple seeds—or rather, a seed factory function. For each thread, it executes this function to generate a separate seed, which becomes a `thread-local accumulator` into which it locally aggregates elements.
  - A `thread-local accumulator` is a separate variable for each thread that participates in parallel processing. It is used to locally aggregate elements in that thread and is not shared with other threads. Each thread executes its own instance of the supplied delegate on its own set of elements and accumulates the result in its own local accumulator. Once all the elements have been processed, these local accumulators are merged together to produce a final result. This approach avoids the need for synchronization between threads, resulting in improved parallel performance.


You must also supply a function to indicate how to combine the local and main accumulators. Finally, this Aggregate overload (somewhat gratuitously) expects a delegate to perform any final transformation on the result (you can achieve this as easily by running some function on the result yourself afterward). So, here are the four delegates, in the order they are passed:
  - `seedFactory`: Returns a new local accumulator
  - `updateAccumulatorFunc`: Aggregates an element into a local accumulator
  - `combineAccumulatorFunc`: Combines a local accumulator with the main accumulator
  - `resultSelector`: Applies any final transformation on the end result

This example is contrived in that we could get the same answer just as efficiently using simpler approaches (such as an unseeded aggregate, or better, the Sum oper‐ ator). To give a more realistic example, suppose that we want to calculate the fre‐ quency of each letter in the English alphabet in a given string. A simple sequential solution might look like this:

```c#
 string text = "Let’s suppose this is a really long string";
    var letterFrequencies = new int[26];
    foreach (char c in text)
    {
      int index = char.ToUpper (c) - 'A';
      if (index >= 0 && index < 26) letterFrequencies [index]++;
    };

```
An example of when the input text might be very long is in gene sequencing. The “alphabet” would then consist of the letters a, c, g, and t.


To parallelize this, we could replace the foreach statement with a call to Paral lel.ForEach (which we cover in the following section), but this will leave us to deal with concurrency issues on the shared array. And locking around accessing that array would all but kill the potential for parallelization.
Aggregate offers a tidy solution. The accumulator, in this case, is an array just like the letterFrequencies array in our preceding example. Here’s a sequential version using Aggregate:
```c#

string text = "Let’s suppose this is a really long string";
int[] result = text.AsParallel().Aggregate (
 () => new int[26],             // Create a new local accumulator
 (localFrequencies, c) =>       // Aggregate into the local accumulator
 {
  int index = char.ToUpper (c) - 'A';
  if (index >= 0 && index < 26) localFrequencies [index]++;
  return localFrequencies;
 },
 (mainFreq, localFreq) =>
// Aggregate local->main accumulator
  mainFreq.Zip (localFreq, (f1, f2) => f1 + f2).ToArray(),
 finalResult => finalResult     // Perform any final transformation
);                               // on the end result.
Console.WriteLine($"total: {JsonConvert.SerializeObject(result)}");
```
`Note`: Notice that the local accumulation function mutates the localFrequencies array. This ability to perform this optimization is important—and is legitimate because `localFrequencies is local to each thread.`

# What is thead-loacl accumulator?
A thread-local accumulator is a separate variable for each thread that participates in parallel processing. It is used to locally aggregate elements in that thread and is not shared with other threads. Each thread executes its own instance of the supplied delegate on its own set of elements and accumulates the result in its own local accumulator. Once all the elements have been processed, these local accumulators are merged together to produce a final result. This approach avoids the need for synchronization between threads, resulting in improved parallel performance.
```c#
List<int> numbers = new List<int> { 1, 2, 3, 4, 5 };
List<int> results = new List<int>();

var aggResult = numbers.AsParallel().Aggregate(
    results,   // seed value
    (acc, n) => { acc.Add(n); return acc; },   // aggregation function
    acc => acc   // result selector
);

Console.WriteLine(string.Join(", ", aggResult));   // output: 1, 2, 3, 4, 5

```
In PLINQ, when you use an explicitly specified seed value for an aggregation operation, that value is shared by all threads involved in the operation. This is not a problem if the seed value is a value type (such as int or double) or an immutable reference type (such as string or DateTime), because these types cannot be modified once created. However, if the seed value is a mutable reference type (such as a custom class instance), then all threads will be accessing the same instance of that object, which can lead to data race conditions and incorrect results.

For example, consider the following code snippet that uses a mutable reference type as the seed value for an aggregation operation:
```c#
List<int> numbers = new List<int> { 1, 2, 3, 4, 5 };
List<int> results = new List<int>();

var aggResult = numbers.AsParallel().Aggregate(
    results,   // seed value
    (acc, n) => { acc.Add(n); return acc; },   // aggregation function
    acc => acc   // result selector
);

Console.WriteLine(string.Join(", ", aggResult));   // output: 1, 2, 3, 4, 5

```
In this example, the seed value is a List<int> instance, which is used to accumulate the elements of the input sequence. However, because the same List<int> instance is shared by all threads, concurrent modifications to it can occur, leading to unexpected behavior. In this case, the aggregation function simply adds each element of the input sequence to the list, so the final result is correct, but this is not guaranteed in general.

To avoid this issue, you can use a seed factory function that generates a new instance of the mutable reference type for each thread, ensuring that each thread has its own local accumulator.
Fix it 
```c#
var data = new List<MyClass>(); // assume MyClass has a property called Value

// create a seed factory function that returns a new instance of the accumulator
Func<MyClass> seedFactory = () => new MyClass();

// define the aggregation function that updates the local accumulator
Func<MyClass, MyClass, MyClass> aggregationFunc = (localAccumulator, item) =>
{
    localAccumulator.Value += item.Value; // assume MyClass has a property called Value
    return localAccumulator;
};

// define the function that combines the local accumulators at the end
Func<MyClass, MyClass, MyClass> combineFunc = (accumulator1, accumulator2) =>
{
    accumulator1.Value += accumulator2.Value;
    return accumulator1;
};

// perform the aggregation using PLINQ
var result = data.AsParallel()
                 .Aggregate(seedFactory, aggregationFunc, combineFunc);

// the result is a single instance of MyClass that contains the sum of all Values in the data list

```