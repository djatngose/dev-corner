# Range partition
Range partitioning is a parallelization technique used in C# for dividing a large input data set into smaller, non-overlapping ranges and processing each range independently in parallel. It works by dividing the input data into ranges based on a key, such as a numerical value or a string, that can be used to sort or partition the data.

In range partitioning, each range is assigned to a separate worker thread, which processes the data within that range independently of the other threads. The output of each worker thread is then merged with the output of the other threads to produce the final result.

Range partitioning can improve performance and scalability for processing large data sets, particularly when the processing time per range is roughly the same and the data can be easily partitioned into non-overlapping ranges.

Here's an example of how range partitioning might work:

Suppose we have a large array of integers, and we want to compute the sum of all the even numbers in the array. We can use range partitioning to divide the array into smaller ranges and compute the sum of the even numbers in each range in parallel.

1. First, we divide the array into non-overlapping ranges based on the index position of the elements. For example, we might divide the array into four ranges:
Range 1: elements 0-24
Range 2: elements 25-49
Range 3: elements 50-74
Range 4: elements 75-99

2. Next, we assign each range to a separate worker thread, which processes the even numbers in that range independently of the other threads.

3. Each worker thread computes the sum of the even numbers in its assigned range, and returns that sum as its output.

4. The output of each worker thread is then merged with the output of the other threads to produce the final result, which is the sum of all the even numbers in the array.

By dividing the input array into smaller, non-overlapping ranges and processing each range independently in parallel, we can improve the performance and scalability of the computation.

`Note`: `Range partitioning doesn’t necessarily allocate element ranges in contiguous blocks—it might instead choose a “striping” strategy`. For instance, if there are two workers, one worker might process odd-numbered elements while the other pro‐ cesses even-numbered elements. The TakeWhile operator is almost certain to trigger a striping strategy to avoid unneces‐ sarily processing elements later in the sequence.
```c#
List<int> numbers = Enumerable.Range(1, 1000000).ToList(); // a list of integers from 1 to 1,000,000

var evenWorkerResult = numbers.TakeWhile((num, index) => index % 2 == 0); // get even-numbered elements
var oddWorkerResult = numbers.TakeWhile((num, index) => index % 2 == 1); // get odd-numbered elements

// process evenWorkerResult and oddWorkerResult in parallel using two separate threads or tasks

```
The `TakeWhile` operator returns a sequence of elements that satisfy the condition defined in the lambda expression. In this case, the evenWorkerResult variable will contain all even-numbered elements from the beginning of the list until the first odd-numbered element, and the oddWorkerResult variable will contain all odd-numbered elements from the beginning of the list until the first even-numbered element.

We can then process these two sequences of elements in parallel using two separate threads or tasks, which can help improve the performance of our program by utilizing multiple CPU cores or processors.

# Example
Range partitioning bypasses the normal input-side enumeration and preallocates an equal number of elements to each worker, avoiding contention on the input sequence. But if some threads happen to get easy elements and finish early, they sit idle while the remaining threads continue working. Our earlier prime number calculator might perform poorly with range partitioning. An example of when range partitioning would do well is in calculating the sum of the square roots of the first 10 million integers:
```c#
ParallelEnumerable.Range (1, 10000000).Sum (i => Math.Sqrt (i))
```
Range partitioning works well for calculating the sum of square roots of the first 10 million integers because each worker is assigned a continuous block of integers to work on, so they are all guaranteed to have a similar workload. The calculation of the square root of each integer is also a computationally expensive operation that takes roughly the same amount of time for each integer, so there is less likelihood of some threads finishing early and sitting idle.

On the other hand, range partitioning can perform poorly for prime number calculation because determining whether a number is prime or not is an expensive operation that can take a variable amount of time depending on the number being tested. So if one thread happens to get a block of numbers that are all prime, it will finish its work much faster than the other threads, causing it to sit idle while the other threads continue working on their more complex calculations. In contrast, with chunk partitioning, each thread grabs a small chunk of numbers at a time, ensuring that they are all kept busy with a similar workload.

# Use cases
Range Partitioning:
- When the size of the input data is known in advance
- When the processing time per range is roughly the same
- When the data can be easily partitioned into non-overlapping ranges
- When the data size is large

Examples of use cases for range partitioning include:
  - Sorting or searching large arrays or databases
  - Data aggregation or reduction, such as computing the average of a large set of numbers
  - Generating large reports or summaries
