# Concurrent queue
`ConcurrentQueue<T> `is implemented as a `linked list of segments`. Each segment contains a fixed number of elements and is treated as a separate queue. When a segment becomes full, a new segment is allocated and added to the end of the list. This allows for concurrent additions and removals of elements to occur without requiring locks or other synchronization mechanisms.
# When to use it?

`Producer-consumer scenarios`: In a producer-consumer scenario, one or more threads are producing items to be consumed by one or more consumer threads. A ConcurrentQueue can be used to store the items produced by the producers and allow the consumers to dequeue and process them without blocking or interfering with each other.

`Parallel processing`: In parallel processing scenarios, multiple threads or tasks are working on the same problem concurrently. A ConcurrentQueue can be used to store tasks or work items that need to be processed, allowing the threads or tasks to dequeue and process them without blocking or interfering with each other.

`Event-driven programming`: In event-driven programming, multiple threads or tasks may be waiting for events to occur, and the events may occur in any order or concurrently. A ConcurrentQueue can be used to store the events as they occur, allowing the threads or tasks to dequeue and process them in the order they were received.

# How it works behind the scene?
`ConcurrentQueue` is implemented using a linked list of bounded ring buffers, where each buffer is a contiguous block of memory that stores the elements of the queue. The linked list of buffers is maintained using two pointers: a head pointer and a tail pointer.

Initially, the queue is empty and both the head and tail pointers point to the same buffer. As elements are enqueued into the queue, they are added to the buffer pointed to by the tail pointer. When the buffer becomes full, a new buffer is allocated and added to the end of the linked list, and the tail pointer is updated to point to the new buffer.

When elements are dequeued from the queue, they are removed from the buffer pointed to by the head pointer. If the buffer becomes empty, the head pointer is updated to point to the next buffer in the linked list. If the head pointer catches up with the tail pointer (i.e., all buffers in the linked list are empty), the queue is considered empty.

To ensure thread-safety, the head and tail pointers are updated using atomic operations. Additionally, each buffer in the linked list is isolated from other buffers using padding to avoid false sharing, and the Volatile.Read and SpinWait methods are used to ensure visibility and avoid contention.

Overall, ConcurrentQueue provides a lock-free implementation of a thread-safe, unbounded queue, which can be used in high-concurrency scenarios where multiple threads may need to access the queue simultaneously.

`SpinWait` is a method that allows a thread to spin for a specified number of iterations while waiting for a condition to be satisfied, instead of blocking the thread. This technique is called spinning, and it can be more efficient than blocking if the expected wait time is short. SpinWait also includes a backoff mechanism that reduces CPU usage if the wait time exceeds a certain threshold.
`The Slot class` is used in .NET to provide a thread-safe mechanism for storing thread-local data. Each thread has a separate set of slots that can be used to store data that is specific to that thread. When a thread accesses a slot, it is guaranteed to access the most recent value that was stored in that slot by that thread.
`Volatile.Read()` is a method that provides a memory barrier and prevents the compiler and the CPU from reordering memory operations. It ensures that a read operation is performed on the most up-to-date value of a variable, rather than a stale or outdated value that may have been cached by the CPU. This is especially important in multi-threaded environments, where threads may be accessing shared variables concurrently.
`InitialSegmentLength`: This is a constant that defines the initial length of the segments used in the queue.
`MaxSegmentLength`: This is a constant that defines the maximum length of the segments used in the queue. If the number of items in the queue exceeds this limit, a new segment is created and linked from the current tail segment.
`_crossSegmentLock`: This is a lock object used to protect cross-segment operations, including any updates to _tail or _head, and any operations that need to get a consistent view of them.
`_tail`: This is a reference to the current tail segment of the queue, which is where new items are added via Enqueue operations.
`_head`: This is a reference to the current head segment of the queue, which is where items are removed via TryDequeue operations. As old segments are consumed by dequeues, the head reference is updated to point to the segment that dequeuers should try next.
```c#
/// <summary>Adds an object to the end of the <see cref="ConcurrentQueue{T}"/>.</summary>
        /// <param name="item">
        /// The object to add to the end of the <see cref="ConcurrentQueue{T}"/>.
        /// The value can be a null reference (Nothing in Visual Basic) for reference types.
        /// </param>
        public void Enqueue(T item)
        {
            // Try to enqueue to the current tail.
            if (!_tail.TryEnqueue(item))
            {
                // If we're unable to, we need to take a slow path that will
                // try to add a new tail segment.
                EnqueueSlow(item);
            }
        }

        /// <summary>Adds to the end of the queue, adding a new segment if necessary.</summary>
        private void EnqueueSlow(T item)
        {
            while (true)
            {
                ConcurrentQueueSegment<T> tail = _tail;

                // Try to append to the existing tail.
                if (tail.TryEnqueue(item))
                {
                    return;
                }

                // If we were unsuccessful, take the lock so that we can compare and manipulate
                // the tail.  Assuming another enqueuer hasn't already added a new segment,
                // do so, then loop around to try enqueueing again.
                lock (_crossSegmentLock)
                {
                    if (tail == _tail)
                    {
                        // Make sure no one else can enqueue to this segment.
                        tail.EnsureFrozenForEnqueues();

                        // We determine the new segment's length based on the old length.
                        // In general, we double the size of the segment, to make it less likely
                        // that we'll need to grow again.  However, if the tail segment is marked
                        // as preserved for observation, something caused us to avoid reusing this
                        // segment, and if that happens a lot and we grow, we'll end up allocating
                        // lots of wasted space.  As such, in such situations we reset back to the
                        // initial segment length; if these observations are happening frequently,
                        // this will help to avoid wasted memory, and if they're not, we'll
                        // relatively quickly grow again to a larger size.
                        int nextSize = tail._preservedForObservation ? InitialSegmentLength : Math.Min(tail.Capacity * 2, MaxSegmentLength);
                        var newTail = new ConcurrentQueueSegment<T>(nextSize);

                        // Hook up the new tail.
                        tail._nextSegment = newTail;
                        _tail = newTail;
                    }
                }
            }
        }

        /// <summary>
        /// Attempts to remove and return the object at the beginning of the <see
        /// cref="ConcurrentQueue{T}"/>.
        /// </summary>
        /// <param name="result">
        /// When this method returns, if the operation was successful, <paramref name="result"/> contains the
        /// object removed. If no object was available to be removed, the value is unspecified.
        /// </param>
        /// <returns>
        /// true if an element was removed and returned from the beginning of the
        /// <see cref="ConcurrentQueue{T}"/> successfully; otherwise, false.
        /// </returns>
        public bool TryDequeue([MaybeNullWhen(false)] out T result)
        {
            // Get the current head
            ConcurrentQueueSegment<T> head = _head;

            // Try to take.  If we're successful, we're done.
            if (head.TryDequeue(out result))
            {
                return true;
            }

            // Check to see whether this segment is the last. If it is, we can consider
            // this to be a moment-in-time empty condition (even though between the TryDequeue
            // check and this check, another item could have arrived).
            if (head._nextSegment == null)
            {
                result = default!;
                return false;
            }

            return TryDequeueSlow(out result); // slow path that needs to fix up segments
        }

        /// <summary>Tries to dequeue an item, removing empty segments as needed.</summary>
        private bool TryDequeueSlow([MaybeNullWhen(false)] out T item)
        {
            while (true)
            {
                // Get the current head
                ConcurrentQueueSegment<T> head = _head;

                // Try to take.  If we're successful, we're done.
                if (head.TryDequeue(out item))
                {
                    return true;
                }

                // Check to see whether this segment is the last. If it is, we can consider
                // this to be a moment-in-time empty condition (even though between the TryDequeue
                // check and this check, another item could have arrived).
                if (head._nextSegment == null)
                {
                    item = default;
                    return false;
                }

                // At this point we know that head.Next != null, which means
                // this segment has been frozen for additional enqueues. But between
                // the time that we ran TryDequeue and checked for a next segment,
                // another item could have been added.  Try to dequeue one more time
                // to confirm that the segment is indeed empty.
                Debug.Assert(head._frozenForEnqueues);
                if (head.TryDequeue(out item))
                {
                    return true;
                }

                // This segment is frozen (nothing more can be added) and empty (nothing is in it).
                // Update head to point to the next segment in the list, assuming no one's beat us to it.
                lock (_crossSegmentLock)
                {
                    if (head == _head)
                    {
                        _head = head._nextSegment;
                    }
                }
            }
        }
```

```c#
class ConcurrentQueueSegment{

   /// <summary>Tries to peek at an element from the queue, without removing it.</summary>
        public bool TryPeek([MaybeNullWhen(false)] out T result, bool resultUsed)
        {
            if (resultUsed)
            {
                // In order to ensure we don't get a torn read on the value, we mark the segment
                // as preserving for observation.  Additional items can still be enqueued to this
                // segment, but no space will be freed during dequeues, such that the segment will
                // no longer be reusable.
                _preservedForObservation = true;
                Interlocked.MemoryBarrier();
            }

            Slot[] slots = _slots;

            // Loop in case of contention...
            SpinWait spinner = default;
            while (true)
            {
                // Get the head at which to try to peek.
                int currentHead = Volatile.Read(ref _headAndTail.Head);
                int slotsIndex = currentHead & _slotsMask;

                // Read the sequence number for the head position.
                int sequenceNumber = Volatile.Read(ref slots[slotsIndex].SequenceNumber);

                // We can peek from this slot if it's been filled by an enqueuer, which
                // would have left the sequence number at pos+1.
                int diff = sequenceNumber - (currentHead + 1);
                if (diff == 0)
                {
                    result = resultUsed ? slots[slotsIndex].Item! : default!;
                    return true;
                }
                else if (diff < 0)
                {
                    // The sequence number was less than what we needed, which means this slot doesn't
                    // yet contain a value we can peek, i.e. the segment is empty.  Technically it's
                    // possible that multiple enqueuers could have written concurrently, with those
                    // getting later slots actually finishing first, so there could be elements after
                    // this one that are available, but we need to peek in order.  So before declaring
                    // failure and that the segment is empty, we check the tail to see if we're actually
                    // empty or if we're just waiting for items in flight or after this one to become available.
                    bool frozen = _frozenForEnqueues;
                    int currentTail = Volatile.Read(ref _headAndTail.Tail);
                    if (currentTail - currentHead <= 0 || (frozen && (currentTail - FreezeOffset - currentHead <= 0)))
                    {
                        result = default;
                        return false;
                    }

                    // It's possible it could have become frozen after we checked _frozenForEnqueues
                    // and before reading the tail.  That's ok: in that rare race condition, we just
                    // loop around again. This is not necessarily an always-forward-progressing
                    // situation since this thread is waiting for another to write to the slot and
                    // this thread may have to check the same slot multiple times. Spin-wait to avoid
                    // a potential busy-wait, and then try again.
                    spinner.SpinOnce(sleep1Threshold: -1);
                }
                else
                {
                    // The item was already dequeued by another thread. The head has already been updated beyond what was
                    // observed above, and the sequence number observed above as a volatile load is more recent than the update
                    // to the head. So, the next iteration of the loop is guaranteed to see a new head. Since this is an
                    // always-forward-progressing situation, there's no need to spin-wait before trying again.
                }
            }
        }
}
```