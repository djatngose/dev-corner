# Parallel.For and Parallel.ForEach
`Parallel.For `and `Parallel.ForEach` perform the equivalent of a C# for and foreach loop but with each iteration executing in parallel instead of sequentially. Here are their (simplest) signatures:
```c#
public static ParallelLoopResult For (int fromInclusive, int toExclusive, Action<int> body);
public static ParallelLoopResult ForEach<TSource> ( IEnumerable<TSource> source, Action<TSource> body)
```
This sequential for loop:
```c#
for (int i = 0; i < 100; i++)
Foo (i);
```
is parallelized like this:
```c#
Parallel.For (0, 100, i => Foo (i));
```
 or more simply:
```c#
Parallel.For (0, 100, Foo); And this sequential foreach:
    foreach (char c in "Hello, world")
      Foo (c);
```
is parallelized like this:
```c#
Parallel.ForEach ("Hello, world", Foo);
```
To give a practical example, if we import the System.Security.Cryptography namespace, we can generate six public/private keypair strings in parallel, as follows:
```c#
var keyPairs = new string[6];
Parallel.For (0, keyPairs.Length,
i => keyPairs[i] = RSA.Create().ToXmlString (true));
```
As with Parallel.Invoke, we can feed Parallel.For and Parallel.ForEach a large number of work items and they’ll be efficiently partitioned onto a few tasks.

The latter query could also be done with PLINQ:
```c#
string[] keyPairs =
ParallelEnumerable.Range (0, 6)
.Select (i => RSA.Create().ToXmlString (true)) .ToArray();
```

# Parallel.ForeachAsync vs Task.WhenALl 
The simplest way to put it (and there are always exceptions) is that 
- `Parallel ForEach` is good to speed up CPU bound work (e.g. number crunching)
- `Task.WhenAll` is good when you can fire off lots of IO bound tasks (e.g. HTTP requests, database calls) and wait for them to finish.

If I wanted to do `multiple complex calculations at the same time to get the results faster, I would use Parallel.ForEach.`

If my application needed to get data from two other services via `http`, I would use `WhenAll.` The first task would start and make an http call. While waiting for data the second task would run and make an http call. WhenAll returns when both are done, so it would be faster than waiting for the first http call and then the second in sequence.

# Outer versus inner loops
`Parallel.For and Parallel.ForEach` usually` work best on outer rather than inner loops`. This is because with the former, you’re offering larger chunks of work to parallelize, diluting the management overhead. Parallelizing both inner and outer loops is usually unnecessary. In the following example, we’d typically need more than `100 cores` to benefit from the inner parallelization:
```c#
    Parallel.For (0, 100, i =>
    {
      Parallel.For (0, 50, j => Foo (i, j));   // Sequential would be better
    });                                        // for the inner loop.
```

# Indexed Parallel.ForEach

Sometimes, it’s useful to know the loop iteration index. With a sequential foreach, it’s easy:
```c#
int i = 0;
foreach (char c in "Hello, world") Console.WriteLine (c.ToString() + i++);
```
Incrementing a shared variable, however, is not thread-safe in a parallel context. You must instead use the following version of ForEach:
```c#
public static ParallelLoopResult ForEach<TSource> (
IEnumerable<TSource> source, Action<TSource,ParallelLoopState,long> body)
```
We’ll ignore ParallelLoopState (which we cover in the following section). For now, we’re interested in Action’s third type parameter of type long, which indicates the loop index:
```c
    Parallel.ForEach ("Hello, world", (c, state, i) =>
    {
       Console.WriteLine (c.ToString() + i);
    });
```
To put this into a practical context, let’s revisit the spellchecker that we wrote with PLINQ. The following code loads up a dictionary along with an array of a million words to test:
```c#
if (!File.Exists ("WordLookup.txt"))    // Contains about 150,000 words
      new WebClient().DownloadFile (
        "http://www.albahari.com/ispell/allwords.txt", "WordLookup.txt");
    var wordLookup = new HashSet<string> (
      File.ReadAllLines ("WordLookup.txt"),
      StringComparer.InvariantCultureIgnoreCase);
    var random = new Random();
    string[] wordList = wordLookup.ToArray();
    string[] wordsToTest = Enumerable.Range (0, 1000000)
      .Select (i => wordList [random.Next (0, wordList.Length)])
      .ToArray();
    wordsToTest [12345] = "woozsh";     // Introduce a couple
    wordsToTest [23456] = "wubsie";     // of spelling mistakes.
```

We can perform the spellcheck on our wordsToTest array using the indexed version of `Parallel.ForEach`, as follows:
```c#
if (!File.Exists ("WordLookup.txt"))    // Contains about 150,000 words
      new WebClient().DownloadFile (
        "http://www.albahari.com/ispell/allwords.txt", "WordLookup.txt");
    var wordLookup = new HashSet<string> (
      File.ReadAllLines ("WordLookup.txt"),
      StringComparer.InvariantCultureIgnoreCase);
    var random = new Random();
    string[] wordList = wordLookup.ToArray();
    string[] wordsToTest = Enumerable.Range (0, 1000000)
      .Select (i => wordList [random.Next (0, wordList.Length)])
      .ToArray();
    wordsToTest [12345] = "woozsh";     // Introduce a couple
    wordsToTest [23456] = "wubsie";     // of spelling mistakes.
```

We can perform the spellcheck on our wordsToTest array using the indexed version of Parallel.ForEach, as follows:
```c#
var misspellings = new ConcurrentBag<Tuple<int,string>>();
    Parallel.ForEach (wordsToTest, (word, state, i) =>
    {
      if (!wordLookup.Contains (word))
        misspellings.Add (Tuple.Create ((int) i, word));
});
```
`Notice` that we had to collate the results into a thread-safe collection: having to do this is the disadvantage when compared to using PLINQ. The advantage over PLINQ is that we avoid the cost of applying an indexed Select query operator— which is less efficient than an indexed ForEach.

Let's say we have a large array of integers and we want to find all the numbers that are divisible by 3. We can do this using PLINQ and parallel foreach with indexing as follows:

```c#
int[] numbers = Enumerable.Range(1, 1000000).ToArray();

// Using PLINQ
var plinqResult = numbers
    .AsParallel()
    .Where(n => n % 3 == 0)
    .ToArray();

// Using parallel foreach with indexing
var foreachResult = new ConcurrentBag<int>();
Parallel.ForEach(numbers, (n, state, i) =>
{
    if (n % 3 == 0)
        foreachResult.Add(n);
});
```
Both methods will give us the same result: an array of all the numbers that are divisible by 3. However, there are some differences to consider:

`PLINQ` automatically collates the results into a thread-safe collection, so we don't need to worry about thread safety.
`PLINQ` applies an indexed Select query operator to the input sequence, which can be less efficient than using a simple ForEach loop with indexing.
`Parallel.ForEach` requires us to manually collate the results into a thread-safe collection, but it allows us to use a simple ForEach loop with indexing, which can be more efficient than using an indexed Select query operator.

# ParallelLoopState: Breaking early out of loops
Because the loop body in a parallel For or ForEach is a delegate, you can’t exit the loop early with a break statement. Instead, `you must call Break or Stop on a ParallelLoopState object`:
```c#
  public class ParallelLoopState
    {
      public void Break();
      public void Stop();
      public bool IsExceptional { get; }
      public bool IsStopped { get; }
      public long? LowestBreakIteration { get; }
      public bool ShouldExitCurrentIteration { get; }
}
```
Obtaining a ParallelLoopState is easy: all versions of For and ForEach are over‐ loaded to accept loop bodies of type Action<TSource,ParallelLoopState>. So, to parallelize this:
```c#
foreach (char c in "Hello, world") 
  if (c == ',')
    break;
  else
    Console.Write (c);
```
do this:
```c#
Parallel.ForEach ("Hello, world", (c, loopState) => {
    if (c == ',')
        loopState.Break();
    else
        Console.Write (c);
    });
    // OUTPUT: Hlloe
```
You can see from the output that loop bodies can complete in a random order. Aside from this difference, calling `Break` yields at least the same elements as executing the loop sequentially: this example will always output at least the letters `H, e, l, l, and o in some order`. 

In contrast, calling `Stop` instead of Break `forces all threads to finish immediately after their current iteration`. In our example, calling Stop could give us a subset of the letters H, e, l, l, and o if another thread were lagging behind. Calling Stop is useful when you’ve found something that you’re looking for—or when something has gone wrong and you won’t be looking at the results.

# IsCompleted and LowestBreakIteration
The Parallel.For and Parallel.ForEach methods return a ParallelLoopResult object that exposes properties called `IsCompleted` and `LowestBreakIteration`. These tell you whether the loop ran to completion; if it didn’t, it indicates at what cycle the loop was broken.
If `LowestBreakIteration` returns null, it means that you called Stop (rather than Break) on the loop.

# ShouldExitCurrentIteration
If your loop body is long, you might want other threads to break partway through the method body in case of an early Break or Stop. You can do this by polling the `ShouldExitCurrentIteration` property at various places in your code; this property becomes true immediately after a Stop—or soon after a Break.

When you call Stop or Break on the ParallelLoopState object, it signals to the parallel loop that no further work needs to be done and that the loop should be stopped. However, stopping a parallel loop immediately can be expensive and can cause threads to be left in an undefined state. Therefore, when Stop or Break is called, the loop will continue to execute for a short time to allow all threads to exit gracefully.

During this time, ShouldExitCurrentIteration will return true for all remaining iterations. This property can be checked at various points in your loop body to determine if the current iteration should exit early. This allows you to perform cleanup operations or take other actions before the iteration is stopped.

For example, suppose you have a long-running loop body that performs some computation and you want to break out of the loop as soon as possible when a certain condition is met. You can use ShouldExitCurrentIteration to periodically check if the loop has been stopped and exit the current iteration if it has:

```c#
Parallel.ForEach(data, (item, loopState) =>
{
    // Perform some computation
    ...

    // Check if loop should be stopped
    if (loopState.ShouldExitCurrentIteration)
        return;

    // Perform more computation
    ...

    // Check if loop should be stopped again
    if (loopState.ShouldExitCurrentIteration)
        return;

    // Perform even more computation
    ...
});

```
By checking ShouldExitCurrentIteration at various points in the loop body, you can ensure that your loop can exit early while still allowing all threads to exit gracefully.
# IsExceptional
`IsExceptional` lets you know whether an exception has occurred on another thread. Any unhandled exception will cause the loop to stop after each thread’s current iteration: to avoid this, you must explicitly handle exceptions in your code.

# Optimization with local values
Parallel.For and Parallel.ForEach each offer a set of overloads that feature a generic type argument called TLocal. These overloads are designed to help you optimize the collation of data with iteration-intensive loops. The simplest is this:
```c#
public static ParallelLoopResult For <TLocal> ( int fromInclusive,
int toExclusive,
Func <TLocal> localInit,
Func <int, ParallelLoopState, TLocal, TLocal> body, Action <TLocal> localFinally);
```
These methods are rarely needed in practice because their target scenarios are cov‐ ered mostly by PLINQ (which is fortunate because these overloads are somewhat intimidating!).
Essentially, the problem is this: suppose that we want to sum the square roots of the numbers 1 through 10,000,000. Calculating 10 million square roots is easily par‐ allelizable, but summing their values is troublesome because we must lock around updating the total:
```c#
object locker = new object();
double total = 0;
Parallel.For (1, 10000000,
                  i => { lock (locker) total += Math.Sqrt (i); });
```
he gain from parallelization is more than offset by the cost of obtaining 10 million locks—plus the resultant blocking.
The reality, though, is that we don’t actually need 10 million locks. Imagine a team of volunteers picking up a large volume of litter. If all workers shared a single trash can, the travel and contention would make the process extremely inefficient. The obvious `solution` is for each worker to have a `private or “local” trash can, which is occasionally emptied into the main bin.`


The TLocal versions of For and ForEach work in exactly this way. The volunteers are internal worker threads, and the local value represents a local trash can. For Parallel to do this job, you must feed it two additional delegates that indicate the following:
1. How to initialize a new local value
2. How to combine a local aggregation with the master value


Additionally, instead of the body delegate returning void, it should return the new aggregate for the local value. Here’s our example refactored:
```c#
object locker = new object();
double grandTotal = 0;
Parallel.For(1, 5,
    () => 0.0, // Initialize the local value.
    (i, state, localTotal) =>
        localTotal + i,
    localTotal => // add the local value
    {
        // lock (locker)
         grandTotal += localTotal;
    } // to the master value.
);
```
We must still lock, but only around aggregating the local value to the grand total. This makes the process dramatically more efficient.


## Why we need still the lock?
In the example code you provided, locking is necessary to prevent race conditions when updating the grandTotal variable from multiple threads simultaneously. Even though each thread is maintaining its own local total, they are still ultimately contributing to the same shared grandTotal.

Without the lock statement, multiple threads could try to update grandTotal at the same time, leading to incorrect results due to race conditions. By using the lock statement, we ensure that only one thread at a time can update grandTotal, thereby avoiding race conditions and ensuring correct results.

Note that in this particular example, using a lock statement can lead to reduced parallelism and potentially slower performance, since each thread has to wait for the lock to be released before it can update grandTotal. However, in cases where multiple threads need to update a shared variable, using a lock statement may be necessary to ensure correct results.

# PLINQ for sum

As stated earlier, PLINQ is often a good fit in these scenarios. Our example could be parallelized with PLINQ like this:
```c#
ParallelEnumerable.Range (1, 10000000) .Sum (i => Math.Sqrt (i))
```
`(Notice that we used ParallelEnumerable to force range partitioning: this improves performance in this case because all numbers will take equally long to process.) `
  - because it distributes the work of iterating over the range of numbers across multiple threads in a load-balanced way.
  - Without partitioning, the Parallel.For method will attempt to divide the iterations into chunks of equal size, which may not necessarily be optimal for the particular workload. If the iterations are not uniformly time-consuming, some threads may finish their work much earlier than others, causing idle time for those threads and slowing down the overall performance.
  - By using ParallelEnumerable.Range, the range is automatically partitioned into smaller, more evenly sized ranges, allowing for better load balancing and potentially improved performance.
In more complex scenarios, you might use LINQ’s Aggregate operator instead of Sum. If you supplied a local seed factory, the situation would be somewhat analogous to providing a local value function with Parallel.For.