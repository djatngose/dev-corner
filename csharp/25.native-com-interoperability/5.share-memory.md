# Shared Memory
// 3302410 // 200
Memory-mapped files, or shared memory, is a feature in Windows that allows multi‐ ple processes on the same computer to share data. Shared memory is extremely fast and, unlike pipes, offers random access to the shared data. We saw in Chapter 15 how you can use the MemoryMappedFile class to access memory-mapped files; bypassing this and calling the Win32 methods directly is a good way to demonstrate P/Invoke.
The Win32 CreateFileMapping function allocates shared memory. You tell it how many bytes you need and the name with which to identify the share. Another application can then subscribe to this memory by calling OpenFileMapping with the same name. Both methods return a handle, which you can convert to a pointer by calling MapViewOfFile.
Here’s a class that encapsulates access to shared memory:
```c#
    using System;
    using System.Runtime.InteropServices;
    using System.ComponentModel;
    public sealed class SharedMem : IDisposable
    {
      // Here we're using enums because they're safer than constants
enum FileProtection : uint
{
ReadOnly = 2,
  ReadWrite = 4
}
enum FileRights : uint
{
  Read = 4,
  Write = 2,
  ReadWrite = Read + Write
// constants from winnt.h
// constants from WinBASE.h
}
static readonly IntPtr NoFileHandle = new IntPtr (-1);
[DllImport ("kernel32.dll", SetLastError = true)]
static extern IntPtr CreateFileMapping (IntPtr hFile,
                                        int lpAttributes,
                                        FileProtection flProtect,

                                        uint dwMaximumSizeHigh, uint dwMaximumSizeLow, string lpName);
  [DllImport ("kernel32.dll", SetLastError=true)]
  static extern IntPtr OpenFileMapping (FileRights dwDesiredAccess,
bool bInheritHandle, string lpName);
  [DllImport ("kernel32.dll", SetLastError = true)]
  static extern IntPtr MapViewOfFile (IntPtr hFileMappingObject,
                                      FileRights dwDesiredAccess,
                                      uint dwFileOffsetHigh,
                                      uint dwFileOffsetLow,
                                      uint dwNumberOfBytesToMap);
  [DllImport ("Kernel32.dll", SetLastError = true)]
  static extern bool UnmapViewOfFile (IntPtr map);
  [DllImport ("kernel32.dll", SetLastError = true)]
  static extern int CloseHandle (IntPtr hObject);
  IntPtr fileHandle, fileMap;
  public IntPtr Root => fileMap;
  public SharedMem (string name, bool existing, uint sizeInBytes)
  {
    if (existing)
      fileHandle = OpenFileMapping (FileRights.ReadWrite, false, name);
    else
      fileHandle = CreateFileMapping (NoFileHandle, 0,
                                      FileProtection.ReadWrite,
                                      0, sizeInBytes, name);
    if (fileHandle == IntPtr.Zero)
      throw new Win32Exception();
    // Obtain a read/write map for the entire file
    fileMap = MapViewOfFile (fileHandle, FileRights.ReadWrite, 0, 0, 0);
    if (fileMap == IntPtr.Zero)
      throw new Win32Exception();
}
  public void Dispose()
  {
if (fileMap != IntPtr.Zero) UnmapViewOfFile (fileMap); if (fileHandle != IntPtr.Zero) CloseHandle (fileHandle); fileMap = fileHandle = IntPtr.Zero;
} }
```

In this example, we set SetLastError=true on the DllImport methods that use the SetLastError protocol for emitting error codes. This ensures that the Win32Excep tion is populated with details of the error when that exception is thrown. (It also allows you to query the error explicitly by calling Marshal.GetLastWin32Error.)
To demonstrate this class, we need to run two applications. The first one creates the shared memory, as follows:
    using (SharedMem sm = new SharedMem ("MyShare", false, 1000))
    {
      IntPtr root = sm.Root;
      // I have shared memory!
      Console.ReadLine();         // Here's where we start a second app...
    }
The second application subscribes to the shared memory by constructing a Share dMem object of the same name, with the existing argument true:
    using (SharedMem sm = new SharedMem ("MyShare", true, 1000))
    {
      IntPtr root = sm.Root;
      // I have the same shared memory!
      // ...
}
The net result is that each program has an IntPtr—a pointer to the same unman‐ aged memory. The two applications now need somehow to read and write to memory via this common pointer. One approach is to write a class that encapsulates all the shared data and then serialize (and deserialize) the data to the unmanaged memory using an UnmanagedMemoryStream. This is inefficient, however, if there’s a lot of data. Imagine if the shared memory class had a megabyte of data, and just one integer needed to be updated. A better approach is to define the shared data construct as a struct and then map it directly into shared memory. We discuss this in the following section.

# Mapping a Struct to Unmanaged Memory
You can directly map a struct with a StructLayout of Sequential or Explicit into unmanaged memory. Consider the following struct:
[StructLayout (LayoutKind.Sequential)] unsafe struct MySharedData
{
public int Value;
public char Letter;
public fixed float Numbers [50];
}
The fixed directive allows us to define fixed-length value-type arrays inline, and it
is what takes us into the unsafe realm. Space in this struct is allocated inline for 50

floating-point numbers. Unlike with standard C# arrays, Numbers is not a reference to an array—it is the array. If we run the following:
static unsafe void Main() => Console.WriteLine (sizeof (MySharedData));
the result is 208: 50 four-byte floats, plus the four bytes for the Value integer, plus two bytes for the Letter character. The total, 206, is rounded to 208 due to the floats being aligned on four-byte boundaries (four bytes being the size of a float).
We can demonstrate MySharedData in an unsafe context, most simply, with stack- allocated memory:
MySharedData d;
MySharedData* data = &d;
data->Value = 123;
data->Letter = 'X';
data->Numbers[10] = 1.45f;
// Get the address of d
    or:
    // Allocate the array on the stack:
MySharedData* data = stackalloc MySharedData[1];
    data->Value = 123;
    data->Letter = 'X';
    data->Numbers[10] = 1.45f;
Of course, we’re not demonstrating anything that couldn’t otherwise be achieved in a managed context. Suppose, however, that we want to store an instance of MySharedData on the unmanaged heap, outside the realm of the CLR’s garbage collector. This is where pointers become really useful:
MySharedData* data = (MySharedData*)
Marshal.AllocHGlobal (sizeof (MySharedData)).ToPointer();
    data->Value = 123;
    data->Letter = 'X';
    data->Numbers[10] = 1.45f;
Marshal.AllocHGlobal allocates memory on the unmanaged heap. Here’s how to later free the same memory:
Marshal.FreeHGlobal (new IntPtr (data));
(The result of forgetting to free the memory is a good old-fashioned memory leak.)
From .NET 6, you can instead use the new NativeMemory class for allocating and freeing unmanaged memory. NativeMemory uses a newer (and better) underlying API than AllocHGlobal and also includes methods for performing aligned allocations.
In keeping with its name, here we use MySharedData in conjunction with the Share dMem class we wrote in the preceding section. The following program allocates a block of shared memory, and then maps the MySharedData struct into that memory:
```c#
static unsafe void Main()
{
  using (SharedMem sm = new SharedMem ("MyShare", false,
                          (uint) sizeof (MySharedData)))
{
void* root = sm.Root.ToPointer(); MySharedData* data = (MySharedData*) root;
    data->Value = 123;
    data->Letter = 'X';
    data->Numbers[10] = 1.45f;
    Console.WriteLine ("Written to shared memory");
    Console.ReadLine();
    Console.WriteLine ("Value is " + data->Value);
    Console.WriteLine ("Letter is " + data->Letter);
    Console.WriteLine ("11th Number is " + data->Numbers[10]);
    Console.ReadLine();
} }
```c\