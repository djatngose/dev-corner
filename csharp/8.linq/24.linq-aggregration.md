# Aggregation Methods
IEnumerable<TSource>→scalar

Method	Description	SQL equivalents
Count, LongCount	Returns the number of elements in the input sequence, optionally satisfying a predicate	COUNT (...)
Min, Max	Returns the smallest or largest element in the sequence	MIN (...), MAX (...)
Sum, Average	Calculates a numeric sum or average over elements in the sequence	SUM (...), AVG (...)
Aggregate	Performs a custom aggregation	Exception thrown

# Count and LongCount
Argument	Type
Source sequence	IEnumerable<TSource>
Predicate (optional)	TSource => bool
Count simply enumerates over a sequence, returning the number of items:

int fullCount = new int[] { 5, 6, 7 }.Count();    // 3
The internal implementation of Enumerable.Count tests the input sequence to see whether it happens to implement ICollection<T>. If it does, it simply calls ICollection<T>.Count; otherwise, it enumerates over every item, incrementing a counter.

You can optionally supply a predicate:

int digitCount = "pa55w0rd".Count (c => char.IsDigit (c));   // 3
`LongCount does the same job as Count but returns a 64-bit integer, allowing for sequences of greater than two billion elements.`

# Min and Max
Argument	Type
Source sequence	IEnumerable<TSource>
Result selector (optional)	TSource => TResult
Min and Max return the smallest or largest element from a sequence:

int[] numbers = { 28, 32, 14 };
int smallest = numbers.Min();  // 14;
int largest  = numbers.Max();  // 32;
If you include a selector expression, each element is first projected:

int smallest = numbers.Max (n => n % 10);  // 8;
A selector expression is mandatory if the items themselves are not intrinsically comparable—in other words, if they do not implement IComparable<T>:
```c#
Purchase runtimeError = dbContext.Purchases.Min ();             // Error
decimal? lowestPrice = dbContext.Purchases.Min (p => p.Price);  // OK
```
A selector expression determines not only how elements are compared, but also the final result. In the preceding example, the final result is a decimal value, not a purchase object. To get the cheapest purchase, you need a subquery:
```c#
Purchase cheapest = dbContext.Purchases
  .Where (p => p.Price == dbContext.Purchases.Min (p2 => p2.Price))
  .FirstOrDefault();
```
In this case, you could also formulate the query without an aggregation by using an OrderBy followed by FirstOrDefault.

# Sum and Average
Argument	Type
Source sequence	IEnumerable<TSource>
Result selector (optional)	TSource => TResult
Sum and Average are aggregation operators that are used in a similar manner to Min and Max:

decimal[] numbers  = { 3, 4, 8 };
decimal sumTotal   = numbers.Sum();               // 15
decimal average    = numbers.Average();           // 5   (mean value)
The following returns the total length of each of the strings in the names array:

int combinedLength = names.Sum (s => s.Length);   // 19
Sum and Average are fairly restrictive in their typing. Their definitions are hardwired to each of the numeric types (int, long, float, double, decimal, and their nullable versions). In contrast, Min and Max can operate directly on anything that implements IComparable<T>—such as a string, for instance.

Further, Average always returns either decimal, float, or double, according to the following table:

Selector type	Result type
decimal	decimal
float	float
int, long, double	double
This means that the following does not compile (“cannot convert double to int”):

int avg = new int[] { 3, 4 }.Average();
But this will compile:

double avg = new int[] { 3, 4 }.Average();   // 3.5
Average implicitly upscales the input values to prevent loss of precision. In this example, we averaged integers and got 3.5 without needing to resort to an input element cast:

double avg = numbers.Average (n => (double) n);
When querying a database, Sum and Average translate to the standard SQL aggregations. The following query returns customers whose average purchase was more than $500:

from c in dbContext.Customers
where c.Purchases.Average (p => p.Price) > 500
select c.Name;

# Aggregate
Aggregate allows you to specify a custom accumulation algorithm for implementing unusual aggregations. Aggregate is not supported in EF Core and is somewhat specialized in its use cases. The following demonstrates how Aggregate can do the work of Sum:

int[] numbers = { 1, 2, 3 };
int sum = numbers.Aggregate (0, (total, n) => total + n);   // 6
The first argument to Aggregate is the seed, from which accumulation starts. The second argument is an expression to update the accumulated value, given a fresh element. You can optionally supply a third argument to project the final result value from the accumulated value.

NOTE
Most problems for which Aggregate has been designed can be solved as easily with a foreach loop—and with more familiar syntax. The advantage of using Aggregate is that with large or complex aggregations, you can automatically parallelize the operation with PLINQ (see Chapter 22).

# Unseeded aggregations
You can omit the seed value when calling Aggregate, in which case the first element becomes the implicit seed, and aggregation proceeds from the second element. Here’s the preceding example, unseeded:

int[] numbers = { 1, 2, 3 };
int sum = numbers.Aggregate ((total, n) => total + n);   // 6
This gives the same result as before, but we’re actually doing a different calculation. Before, we were calculating 0 + 1 + 2 + 3; now we’re calculating 1 + 2 + 3. We can better illustrate the difference by multiplying instead of adding:

int[] numbers = { 1, 2, 3 };
int x = numbers.Aggregate (0, (prod, n) => prod * n);   // 0*1*2*3 = 0
int y = numbers.Aggregate (   (prod, n) => prod * n);   //   1*2*3 = 6
As you’ll see in Chapter 22, unseeded aggregations have the advantage of being parallelizable without requiring the use of special overloads. However, there are some traps with unseeded aggregations.

# Traps with unseeded aggregations
The unseeded aggregation methods are intended for use with delegates that are commutative and associative. If used otherwise, the result is either unintuitive (with ordinary queries) or nondeterministic (in the case that you parallelize the query with PLINQ). For example, consider the following function:

(total, n) => total + n * n
This is neither commutative nor associative. (For example, 1 + 2 * 2 != 2 + 1 * 1.) Let’s see what happens when we use it to sum the square of the numbers 2, 3, and 4:

int[] numbers = { 2, 3, 4 };
int sum = numbers.Aggregate ((total, n) => total + n * n);    // 27
Instead of calculating

2*2 + 3*3 + 4*4    // 29
it calculates:

2 + 3*3 + 4*4      // 27
We can fix this in a number of ways. First, we could include 0 as the first element:

int[] numbers = { 0, 2, 3, 4 };
Not only is this inelegant, but it will still give incorrect results if parallelized—because PLINQ uses the function’s assumed associativity by selecting multiple elements as seeds. To illustrate, if we denote our aggregation function as follows:

f(total, n) => total + n * n
LINQ to Objects would calculate this:

f(f(f(0, 2),3),4)
whereas PLINQ might do this:

f(f(0,2),f(3,4))
with the following result:

First partition:   a = 0 + 2*2  (= 4)
Second partition:  b = 3 + 4*4  (= 19)
Final result:          a + b*b  (= 365)
OR EVEN:               b + a*a  (= 35) 
There are two good solutions. The first is to turn this into a seeded aggregation with 0 as the seed. The only complication is that with PLINQ, we’d need to use a special overload in order for the query not to execute sequentially (see “Optimizing PLINQ”).

The second solution is to restructure the query such that the aggregation function is commutative and associative:

int sum = numbers.Select (n => n * n).Aggregate ((total, n) => total + n);

NOTE
Of course, in such simple scenarios you can (and should) use the Sum operator instead of Aggregate:

int sum = numbers.Sum (n => n * n);
You can actually go quite far just with Sum and Average. For instance, you can use Average to calculate a root-mean-square:

Math.Sqrt (numbers.Average (n => n * n))
You can even calculate standard deviation:

double mean = numbers.Average();
double sdev = Math.Sqrt (numbers.Average (n =>
              {
                double dif = n - mean;
                return dif * dif;
              }));
Both are safe, efficient, and fully parallelizable. In Chapter 22, we give a practical example of a custom aggregation that can’t be reduced to Sum or Average.