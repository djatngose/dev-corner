# Signaling with Event Wait Handles

`Event wait handles are used for signaling. Signaling is when one thread waits until it receives notification from another.`

The simplest kind of signaling constructs are called event wait handles (unrelated to C# events). `Event wait handles` come in three flavors: `AutoResetEvent`, `Manual ResetEvent(Slim)`, and `CountdownEvent`. The former two are based on the common EventWaitHandle class from which they derive all their functionality.

 In general,
 - `AutoResetEvent` is useful when you need a single thread to wait for a specific event to occur
 - `ManualResetEvent` is useful when you need multiple threads to wait for a single event to occur, and
 - `CountdownEvent` is useful when you need multiple threads to coordinate their execution and complete a specific set of tasks before continuing.

# A Comparison of Signaling Constructs

Construct	Purpose	Cross-process?	Overhead*
`AutoResetEvent`	Allows a thread to unblock once when it receives a signal from another	`Yes`	`1000ns`
`ManualResetEvent`	Allows a thread to unblock indefinitely when it receives a signal from another (until reset)	`Yes`	`1000ns`
`ManualResetEventSlim` (introduced in Framework 4.0)	-	`40ns`
`CountdownEvent` (introduced in Framework 4.0)	Allows a thread to unblock when it receives a predetermined number of signals	-	`40ns`
`Barrier` (introduced in Framework 4.0)	Implements a thread execution barrier	-	`80ns`
`Wait and Pulse`	Allows a thread to block until a custom condition is met	-	`120ns` for a Pulse


# AutoResetEvent
An `AutoResetEvent` is like a ticket turnstile: inserting a ticket lets exactly one person through. The “auto” in the class’s name refers to the fact that an open turnstile automatically closes or “resets” after someone steps through.

An `AutoResetEvent` is a synchronization primitive that allows a thread to wait until a signal is set, at which point it will be automatically reset. Once a thread has been signaled, any subsequent wait operations will block until the signal is reset. `This is useful for scenarios where a single thread needs to wait for a specific event to occur before continuing its execution.`

`Example`: Imagine you have two threads, one that reads from a file and another that writes to a file. You want to ensure that the writer thread does not write to the file until the reader thread has finished reading from it. You could use an AutoResetEvent to signal the writer thread when the reader thread has finished reading from the file:
```c#

AutoResetEvent readerFinished = new AutoResetEvent(false);

new Thread(WriterThread).Start();
new Thread(WriterThread).Start();
new Thread(WriterThread).Start();
new Thread(ReaderThread).Start();
new Thread(WriterThread).Start();

// Reader thread reads from file
void ReaderThread()
{
 // read from file
 Console.WriteLine("Render read starting...");
 readerFinished.Set(); // signal writer thread
 Console.WriteLine("Render read completed...");
}

// Writer thread writes to file
void WriterThread()
{
 readerFinished.WaitOne(); // wait for reader thread to finish
 Console.WriteLine("Process write completed...");
 // write to file
}

//OUTPUT
Render read starting...
Render read completed...
Process write completed...

```
If `Set` is called when no thread is waiting, the handle stays open for as long as it takes until some thread calls WaitOne. This behavior helps avoid a race between a thread heading for the turnstile, and a thread inserting a ticket (“Oops, inserted the ticket a microsecond too soon, bad luck, now you’ll have to wait indefinitely!”). However, calling Set repeatedly on a turnstile at which no one is waiting doesn’t allow a whole party through when they arrive: only the next single person is let through and the extra tickets are “wasted.”


## Disposing Wait Handles
After you’ve finished with a wait handle, you can call its Close method to release the OS resource. Alternatively, you can simply drop all references to the wait handle and allow the garbage collector to do the job for you sometime later (wait handles implement the disposal pattern whereby the finalizer calls Close). This is one of the few scenarios for which relying on this backup is (arguably) acceptable, because wait handles have a light OS burden.
Wait handles are released automatically when a process exits.

# Two-way signaling
Suppose that we want the main thread to signal a worker thread three times in a row. If the main thread simply calls Set on a wait handle several times in rapid succession, the second or third signal can become lost because the worker might take time to process each signal.
The solution is for the main thread to wait until the worker’s ready before signaling it. We can do this by using another AutoResetEvent, as follows:
```c#
    class TwoWaySignaling
    {
static EventWaitHandle _ready = new AutoResetEvent (false); static EventWaitHandle _go = new AutoResetEvent (false); static readonly object _locker = new object();
static string _message;
 static void Main() {
new Thread (Work).Start();
  _ready.WaitOne();
  lock (_locker) _message = "ooo";
_go.Set();
  _ready.WaitOne();
// First wait until worker is ready
// Tell worker to go
lock (_locker) _message = "ahhh";  // Give the worker another message
_go.Set();
_ready.WaitOne();

        lock (_locker) _message = null;
_go.Set();
}
      static void Work()
      {
        while (true)
        {
_ready.Set(); _go.WaitOne(); lock (_locker) {
            if (_message == null) return;
            Console.WriteLine (_message);
          }
} }
}
    // Output:
    ooo
    ahhh
```
# Producer/consumer queue
A producer/consumer queue is a common requirement in threading. Here’s how it works:

  - A queue is set up to describe work items — or data upon which work is performed.
  - When a task needs executing, it’s enqueued, allowing the caller to get on with other things.
  - One or more worker threads plug away in the background, picking off and executing queued items.

The advantage of this model is that you have precise control over how many worker threads execute at once. This can allow you to limit consumption of not only CPU time, but other resources as well. If the tasks perform intensive disk I/O, for instance, you might have just one worker thread to avoid starving the operating system and other applications. Another type of application may have 20. You can also dynamically add and remove workers throughout the queue’s life. The CLR’s thread pool itself is a kind of producer/consumer queue.

A producer/consumer queue typically holds items of data upon which (the same) task is performed. For example, the items of data may be filenames, and the task might be to encrypt those files.

In the example below, we use a single AutoResetEvent to signal a worker, which waits when it runs out of tasks (in other words, when the queue is empty). We end the worker by enqueing a null task:
```c#
using System;
using System.Threading;
using System.Collections.Generic;
 
class ProducerConsumerQueue : IDisposable
{
  EventWaitHandle _wh = new AutoResetEvent (false);
  Thread _worker;
  readonly object _locker = new object();
  Queue<string> _tasks = new Queue<string>();
 
  public ProducerConsumerQueue()
  {
    _worker = new Thread (Work);
    _worker.Start();
  }
 
  public void EnqueueTask (string task)
  {
    lock (_locker) _tasks.Enqueue (task);
    _wh.Set();
  }
 
  public void Dispose()
  {
    EnqueueTask (null);     // Signal the consumer to exit.
    _worker.Join();         // Wait for the consumer's thread to finish.
    _wh.Close();            // Release any OS resources.
  }
 
  void Work()
  {
    while (true)
    {
      string task = null;
      lock (_locker)
        if (_tasks.Count > 0)
        {
          task = _tasks.Dequeue();
          if (task == null) return;
        }
      if (task != null)
      {
        Console.WriteLine ("Performing task: " + task);
        Thread.Sleep (1000);  // simulate work...
      }
      else
        _wh.WaitOne();         // No more tasks - wait for a signal
    }
  }
}
```
To ensure thread safety, we used a lock to protect access to the Queue<string> collection. We also explicitly closed the wait handle in our Dispose method, since we could potentially create and destroy many instances of this class within the life of the application.

Here's a main method to test the queue:
```c#
static void Main()
{
  using (ProducerConsumerQueue q = new ProducerConsumerQueue())
  {
    q.EnqueueTask ("Hello");
    for (int i = 0; i < 10; i++) q.EnqueueTask ("Say " + i);
    q.EnqueueTask ("Goodbye!");
  }
 
  // Exiting the using statement calls q's Dispose method, which
  // enqueues a null task and waits until the consumer finishes.
}
//OUTPUT
Performing task: Hello
Performing task: Say 1
Performing task: Say 2
Performing task: Say 3
...
...
Performing task: Say 9
Goodbye!
```
# ManualResetEvent
This is another synchronization primitive that allows threads to wait for a signal from another thread. It is similar to `AutoResetEvent`, but it has `one key difference: it remains in the signaled state until it is explicitly reset. This means that multiple threads can be released by a single signal, and they will remain unblocked until the event is reset`. This is useful for cases where you want to signal multiple threads at once, such as when multiple threads are waiting for a resource to become available.

From Framework 4.0, there's another version of ManualResetEvent called `ManualResetEventSlim`. The latter is optimized for short waiting times — with the ability to opt into spinning for a set number of iterations. It also has a more efficient managed implementation and allows a Wait to be canceled via a CancellationToken. It cannot, however, be used for interprocess signaling. ManualResetEventSlim doesn’t subclass WaitHandle; however, it exposes a WaitHandle property that returns a WaitHandle-based object when called (with the performance profile of a traditional wait handle).

A `ManualResetEvent` is similar to an AutoResetEvent, but the signal does not automatically reset after a thread has been released. This means that any subsequent wait operations will continue to pass until the signal is manually reset. `This is useful for scenarios where multiple threads need to wait for a single event to occur before continuing their execution.`

As we described in Chapter 14, a ManualResetEvent functions like a simple gate. Calling Set opens the gate, allowing any number of threads calling WaitOne to be let through. Calling Reset closes the gate. Threads that call WaitOne on a closed gate will block; when the gate is next opened, they will be released all at once. Apart from these differences, a ManualResetEvent functions like an AutoResetEvent.
As with AutoResetEvent, you can construct a ManualResetEvent in two ways: var manual1 = new ManualResetEvent (false);
    var manual2 = new EventWaitHandle (false, EventResetMode.ManualReset);

`There’s another version of ManualResetEvent called ManualResetEventSlim.` The latter is optimized for short waiting times —with the ability to opt into spinning for a set number of iter‐ ations. It also has a more efficient managed implementation and allows a Wait to be canceled via a CancellationToken. ManualResetEventSlim doesn’t subclass WaitHandle; however, it exposes a WaitHandle property that returns a WaitHandle- based object when called (with the performance profile of a traditional wait handle).
 
`Example`: Imagine you have a pool of worker threads, and you want to ensure that they do not all try to access a shared resource at the same time. You could use a ManualResetEvent to signal when the resource is available:
```c#

// Create a ManualResetEvent in the non-signaled state
ManualResetEventSlim resourceAvailable = new ManualResetEventSlim(false);

// Worker threads try to access shared resource
void WorkerThread()
{
 Console.WriteLine("worker access starting...");
 resourceAvailable.Wait(); // wait for resource to become available
 // access shared resource
 Console.WriteLine("worker access shared resouce");
}

// Main thread signals that resource is available
void MainThread()
{
 Console.WriteLine("Main thread starting...");
 resourceAvailable.Set(); // signal all waiting worker threads
 Console.WriteLine("Main thread set signaled");
 // Thread.Sleep(2000);
 resourceAvailable.Reset(); // reset event to non-signaled state, cause threads blocked
 Console.WriteLine("Main thread reset state");
}
new Thread(WorkerThread).Start();
new Thread(WorkerThread).Start();
new Thread(WorkerThread).Start();
new Thread(MainThread).Start();
new Thread(WorkerThread).Start();

// OUTPUT
worker access starting...
worker access starting...
worker access starting...
worker access starting...
Main thread starting...
worker access shared resouce
worker access shared resouce
Main thread set signaled
Main thread reset state

```
# Signaling Constructs and Performance
Waiting or signaling an `AutoResetEvent` or `ManualResetEvent` takes about `one microsecond (assuming no blocking)`.

`ManualResetEventSlim` and `CountdownEvent` can be up to 50 times faster in short- wait scenarios because of their nonreliance on the OS and judicious use of spinning constructs. In most scenarios, however, the overhead of the signaling classes them‐ selves doesn’t create a bottleneck; thus, it is rarely a consideration.

# CountdownEvent
A `CountdownEvent` is a synchronization primitive that allows a group of threads to wait until a specific number of signals have been set. Once the countdown reaches zero, all waiting threads will be released. `This is useful for scenarios where multiple threads need to coordinate their execution, and each thread must complete a specific task before the overall operation can continue.`

CountdownEvent lets you wait on more than one thread. The class has an efficient, fully managed implementation. To use the class, instantiate it with the number of threads, or “counts,” that you want to wait on:
var countdown = new CountdownEvent (3); // Initialize with "count" of 3. Calling Signal decrements the “count”; calling Wait blocks until the count goes
down to zero:
```c#
var countdown = new CountdownEvent (5);
new Thread (SaySomething).Start ("I am thread 1");
new Thread (SaySomething).Start ("I am thread 2");
new Thread (SaySomething).Start ("I am thread 3");
countdown.Wait();   // Blocks until Signal has been called 3 times
Console.WriteLine ("All threads have finished speaking!");

void SaySomething(object thing)
{
 Thread.Sleep(1000);
 Console.WriteLine(thing);
 countdown.Signal();
}
```

You can sometimes more easily solve problems for which CountdownEvent is effective by using the structured parallelism constructs that we describe in Chapter 22 (PLINQ and the Parallel class).

`You can reincrement a CountdownEvent’s count by calling AddCount`. However, `if it has already reached zero, this throws an exception: you can’t “unsignal” a Count downEvent by calling AddCount`. To prevent the possibility of an exception being thrown, you can instead call `TryAddCount`, which returns false if the countdown is zero.

To `unsignal a countdown event, call Reset`: this both unsignals the construct and resets its count to the original value.
Like `ManualResetEventSlim`, `CountdownEvent` exposes a WaitHandle property for scenarios in which some other class or method expects an object based on WaitHandle.


# Creating a Cross-Process EventWaitHandle
EventWaitHandle’s constructor allows a “named” EventWaitHandle to be created, capable of operating across multiple processes. The name is simply a string, and it can be any value that doesn’t unintentionally conflict with someone else’s! If the name is already in use on the computer, you get a reference to the same underlying EventWaitHandle; otherwise, the OS creates a new one. Here’s an example:
```c#
    EventWaitHandle wh = new EventWaitHandle (false, EventResetMode.AutoReset,
                                          @"Global\MyCompany.MyApp.SomeName");
```
If two applications each ran this code, they would be able to signal each other: the wait handle would work across all threads in both processes.
Named event wait handles are available only on Windows.

```c#
// Process 1: create the named event wait handle
EventWaitHandle wh = new EventWaitHandle(false, EventResetMode.AutoReset, @"Global\MyCompany.MyApp.SomeName");

// Process 2: open the named event wait handle
EventWaitHandle wh = EventWaitHandle.OpenExisting(@"Global\MyCompany.MyApp.SomeName");

// Process 1: signal the event
wh.Set();

// Process 2: wait for the event
wh.WaitOne();

```
In this example, Process 1 creates a named event wait handle with the name "Global\MyCompany.MyApp.SomeName". Process 2 then opens the same named event wait handle using the same name. Process 1 signals the event using wh.Set(), which unblocks any waiting threads, including those in Process 2. Process 2 waits for the event using wh.WaitOne(), which blocks until the event is signaled.
# Wait Handles and Continuations
If your application has` lots of threads that spend most of their time blocked on a wait handle, you can reduce the resource burden` by calling T`hreadPool.RegisterWaitForSingleObject`. This method accepts a delegate that is executed when a wait handle is signaled. While it’s waiting, it doesn’t tie up a thread:

Rather than waiting on a wait handle (and blocking your thread), you can attach a “continuation” to it by calling ThreadPool.RegisterWaitForSingleObject. This method accepts a delegate that is executed when a wait handle is signaled:

When you call `WaitOne` method on a wait handle, your thread will be blocked and wait for the wait handle to be signaled. However,` if you don't want to block your thread and want to continue executing some other code until the wait handle is signaled, you can use ThreadPool.RegisterWaitForSingleObject method.`
`
This method registers a delegate (also known as a callback) that will be executed when the wait handle is signaled. The delegate will be executed on a thread from the thread pool, so it won't block your main thread.

```c#
var starter = new ManualResetEvent (false);
RegisteredWaitHandle reg = ThreadPool.RegisterWaitForSingleObject(starter, Go, "Some Data", -1, true);
Thread.Sleep (5000);
Console.WriteLine ("Signaling worker...");
 starter.Set();
Console.ReadLine();
reg.Unregister (starter); // Clean up when we’re done.
void Go (object data, bool timedOut)
{
      Console.WriteLine ("Started - " + data);
      // Perform task...
}
// Output:
(5 second delay)
Signaling worker...
Started - Some Data
```
When the wait handle is signaled (or a timeout elapses), the delegate runs on a pooled thread. You are then supposed to call Unregister to release the unmanaged handle to the callback.
In addition to the wait handle and delegate, RegisterWaitForSingleObject accepts a “black box” object that it passes to your delegate method (rather like Parameteri zedThreadStart) as well as a timeout in milliseconds (-1 meaning no timeout) and a Boolean flag indicating whether the request is a one-off rather than recurring.
You can reliably call RegisterWaitForSingleObject only once per wait handle. Calling this method again on the same wait handle causes an intermittent failure, whereby an unsignaled wait handle fires a callback as though it were signaled.
This limitation makes (the nonslim) wait handles poorly suited to asynchronous programming.



