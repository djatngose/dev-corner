# Intro
We cover the multithreading APIs and constructs aimed at leverag‐ ing multicore processors:
• `Parallel LINQ, or PLINQ`
• `TheParallel class`
• `The task parallelism constructs`
• `The concurrent collections`
These constructs are collectively known (loosely) as `Parallel Framework` (PFX). The Parallel class together with the task parallelism constructs is called the `Task Parallel Library` (TPL).

.NET offers a number of additional specialized APIs to help with parallel and asynchronous programming:
  • `System.Threading.Channels.Channel` is a high- performance asynchronous producer/consumer queue, introduced in .NET Core 3.
  • `Microsoft Dataflow `(in the System.Threading.Tasks .Dataflow namespace) is a sophisticated API for creating networks of buffered blocks that execute actions or data transformations in parallel, with a semblance to actor/ agent programming.
  • `Reactive Extensions implements LINQ over IObservable` (an alternative abstraction to IAsyncEnumerable) and excels at combining asynchronous streams. Reactive extensions ships in the System.Reactive NuGet package.

# Why PFX?
Over the past 15 years, CPU manufacturers have shifted from single-core to multi‐ core processors. This is problematic for us as programmers because single-threaded code does not automatically run faster as a result of those extra cores.

Utilizing multiple cores is easy for most server applications, where each thread can independently handle a separate client request, but it’s more difficult on the desktop because it typically requires that you take your computationally intensive code and do the following:
  1. `Partition it into small chunks.`
  2. `Execute those chunks in parallel via multithreading.`
  3. `Collate the results as they become available, in a thread-safe and performant manner.`

Although you can do all of this with the classic multithreading constructs, it’s awkward—particularly the steps of partitioning and collating. A further problem is that the usual strategy of locking for thread safety causes a lot of contention when many threads work on the same data at once.

`Note`: Programming to leverage multicores or multiple processors is called parallel programming. This is a subset of the broader concept of multithreading.

# PFX concepts
There are two strategies for partitioning work among threads: `data parallelism and task parallelism`.
  - When a set of tasks must be performed on many data values, we can parallelize by having each thread perform the (same) set of tasks on a subset of values. This is called `data parallelism` because we are partitioning the data between threads.
  -  In contrast, with `task parallelism` we partition the tasks; in other words, we have each thread perform a different task.

In general, `data parallelism` is easier and scales better to highly parallel hardware because it reduces or eliminates shared data (thereby reducing contention and thread-safety issues). Also, `data parallelism` exploits the fact that there are often more data values than discrete tasks, increasing the parallelism potential.

`Data parallelism` is also conducive to structured parallelism, which means that paral‐ lel work units start and finish in the same place in your program. In contrast, task parallelism tends to be unstructured, meaning that parallel work units may start and finish in places scattered across your program. Structured parallelism is simpler and less error prone and allows you to farm the difficult job of partitioning and thread coordination (and even result collation) out to libraries.

```c#
using System;
using System.Threading.Tasks;

class Program
{
    static void Main(string[] args)
    {
        // Data Parallelism Example
        int[] data = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };
        Parallel.ForEach(data, value =>
        {
            // Perform the same task on each value in parallel
            Console.WriteLine($"Square of {value} is {value * value}");
        });

        // Task Parallelism Example
        Task task1 = Task.Factory.StartNew(() =>
        {
            // Perform Task 1
            Console.WriteLine("Task 1 started");
        });
        Task task2 = Task.Factory.StartNew(() =>
        {
            // Perform Task 2
            Console.WriteLine("Task 2 started");
        });
        Task.WaitAll(task1, task2);
        Console.WriteLine("All tasks completed");
    }
}
```
# which one is better?
The choice between data parallelism and task parallelism depends on the specific problem and hardware architecture. In general, `data parallelism is better suited for problems with large amounts of data that can be partitioned among threads, while task parallelism is better suited for problems with a large number of independent tasks that can be assigned to threads.`

However, in practice, many problems can benefit from a combination of both data and task parallelism. For example, a problem may involve partitioning a large dataset among threads, but each thread may need to perform a set of independent computations on its assigned data. In this case, a hybrid approach that combines data and task parallelism may be the best solution.

Ultimately, the choice of parallelism strategy should be based on careful analysis of the problem, the available hardware, and the performance characteristics of different approaches.
