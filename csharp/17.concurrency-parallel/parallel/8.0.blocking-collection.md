
# BlockingCollection
`BlockingCollection` is a thread-safe collection class in C# that is used to implement producer-consumer scenarios, where one or more producer threads add elements to the collection and one or more consumer threads remove elements from the collection.
It provides blocking semantics, meaning that if a consumer tries to remove an element from an empty collection, it will block (i.e., wait) until an element becomes available. Similarly, if a producer tries to add an element to a full collection, it will block until space becomes available. This makes it a useful tool for coordinating the communication between producer and consumer threads, as it allows them to wait for each other without wasting resources by continually checking for availability.

`BlockingCollection` can be initialized with any of the concurrent collection types, such as ConcurrentQueue or ConcurrentStack, or with a regular collection type such as List or Queue, by using a constructor overload that takes an instance of ICollection<T>. It can also be configured with a bounded capacity, which limits the number of elements it can hold at any given time.

`BlockingCollection` can be used in situations where you have one or more producer threads producing items and one or more consumer threads consuming those items, and you want to ensure that the consumers always have access to the most recent items produced.

One example use case could be in a message processing system where one thread is responsible for receiving messages and adding them to the collection, while another thread is responsible for processing the messages in the collection. The use of `BlockingCollection` ensures that the processing thread always has access to the most recent messages, while also allowing the receiving thread to continue receiving messages without blocking or dropping any.

Another use case could be in a concurrent file processing system where multiple threads are reading and writing to the same file. In this case, `BlockingCollection` can be used to ensure that the writes are synchronized and the order of writes is maintained.

Overall, `BlockingCollection` can be useful in any situation where you need to synchronize access to a collection between multiple threads, and where you want to avoid race conditions, deadlocks, or other synchronization issues.

# Problem
If you call `TryTake` on any of the `producer/consumer collections` we discussed in the previous section, `ConcurrentStack<T>, ConcurrentQueue<T>, and Concurrent Bag<T>`, and the collection is empty, the method returns false. Sometimes, it would be more useful in this scenario to wait until an element is available.

Rather than overloading the `TryTake` methods with this functionality (which would have caused a blowout of members after allowing for cancellation tokens and timeouts), PFX’s designers encapsulated this functionality into a wrapper class called `BlockingCollection<T>`.

A blocking collection wraps any collection that implements `IProducerConsumerCollection<T>` and lets you Take an element from the wrapped collection`—blocking if no element is available`.

A `blocking collection` also lets you limit the total size of the collection, blocking the producer if that size is exceeded. A collection limited in this manner is called a bounded blocking collection.

To use BlockingCollection<T>:
  1. Instantiate the class, optionally specifying the IProducerConsumerCollection<T> to wrap, and the maximum size (bound) of the collection.
  2. Call Add or TryAdd to add elements to the underlying collection.
  3. Call Take or TryTake to remove (consume) elements from the underlying collection.

If you call the constructor without passing in a collection, the class will automati‐ cally instantiate a `ConcurrentQueue<T>`. The producing and consuming methods let you specify cancellation tokens and timeouts. `Add and TryAdd` may block if the collection size is bounded; `Take and TryTake` block while the collection is empty.

```c#
 /// <summary>Initializes a new instance of the <see cref="T:System.Collections.Concurrent.BlockingCollection`1" /> class without an upper-bound.</summary>
public BlockingCollection() : this((IProducerConsumerCollection<T>) new ConcurrentQueue<T>())
{
}

/// <summary>Initializes a new instance of the <see cref="T:System.Collections.Concurrent.BlockingCollection`1" /> class with the specified upper-bound.</summary>
/// <param name="boundedCapacity">The bounded size of the collection.</param>
/// <exception cref="T:System.ArgumentOutOfRangeException">The <paramref name="boundedCapacity" /> is not a positive value.</exception>
public BlockingCollection(int boundedCapacity): this((IProducerConsumerCollection<T>) new ConcurrentQueue<T>(), boundedCapacity)
{
}
```

# Consume message
Call `Take or TryTake to remove (consume)` elements from the underlying collection.

Another way to consume elements is to call `GetConsumingEnumerable`. This returns a (potentially) infinite sequence that yields elements as they become available. You can force the sequence to end by calling `CompleteAdding`: this method also prevents further elements from being enqueued.

`BlockingCollection` also provides static methods called AddToAny and TakeFrom Any, which let you add or take an element while specifying several blocking collec‐ tions. The action is then honored by the first collection able to service the request.

# How it works?
A `producer/consumer queue` is a useful structure, both in parallel programming and general concurrency scenarios. Here’s how it works:
  - A `queue(ConcurrentQueue)` is set up to describe work items—or data upon which work is performed.
  - When a task needs executing, it’s enqueued, and the caller gets on with other things.
  - One or more worker threads plug away in the background, picking off and executing queued items. It means that there is a separate thread or threads (referred to as "worker threads") that are continuously running in the background and processing items from the queue as they become available.

In general, When a task is enqueued, it is added to the back of the queue, and the caller can continue with other work without waiting for the task to complete. Meanwhile, the worker threads are constantly monitoring the queue, and when they detect an item in the queue, they "pick it off" by dequeuing it from the front of the queue and executing the task associated with that item.  This allows the caller to submit work items asynchronously, without blocking or waiting for the results, while the worker threads execute the tasks in the background. This can be a very effective way of parallelizing workloads and improving overall system performance.

`A producer/consumer queue` gives you precise control over how many worker threads execute at once, which is useful in limiting not only CPU consumption but other resources as well.
  -  If the tasks perform intensive disk I/O, for instance, you can l`imit concurrency to avoid starving the operating system and other applications`.
  -  You can also dynamically add and remove workers throughout the queue’s life. `The CLR’s thread pool itself is a kind of producer/consumer queue`, optimized for short-running compute-bound jobs.

`A producer/consumer` queue typically holds items of data upon which (the same) task is performed. For example, the items of data may be filenames, and the task might be to encrypt those files. By making the item a delegate, however, you can write a more general-purpose producer/consumer queue where each item can do anything.
  - This means that each item in the queue can represent a different method with different arguments, rather than just a piece of data.
  - By using delegates as items in the BlockingCollection, you can create a more general-purpose queue that can execute any type of task, not just tasks that operate on a specific type of data. This allows for greater flexibility and reusability of the queue in different scenarios. For example, you could use a single BlockingCollection to handle different types of tasks, such as file encryption, image processing, or network communication, simply by enqueuing different delegates that perform those tasks.

At http://albahari.com/threading, we show how to `write a producer/consumer queue from scratch using an AutoResetEvent (and later, using Monitor’s Wait and Pulse)`. However, writing a producer/consumer from scratch is unnecessary because most of the functionality is provided by BlockingCollection<T>. Here’s how to use it:
```c#

public class PCQueue : IDisposable
{
    BlockingCollection<Action> _taskQ = new BlockingCollection<Action>();

    public PCQueue(int workerCount)
    {
        // Create and start a separate Task for each consumer:
        for (int i = 0; i < workerCount; i++)
            Task.Factory.StartNew(Consume);
    }

    public void Enqueue(Action action)
    {
        _taskQ.Add(action);
    }

    void Consume()
    {
        // This sequence that we’re enumerating will block when no elements // are available and will end when CompleteAdding is called.
        foreach (Action action in _taskQ.GetConsumingEnumerable()) action(); // Perform task.
    }

    public void Dispose()
    {
        _taskQ.CompleteAdding();
    }
}
```
Because we `didn’t pass anything into BlockingCollection’s constructor`, it instantiated a `concurrent queue automatically`. Had we passed in a `ConcurrentStack`, we’d have ended up with a `producer/consumer stack`.

# Using Tasks
The `producer/consumer` that we just wrote is inflexible in that we can’t track work items after they’ve been enqueued. It would be nice if we could do the following:
  - Know when a work item has completed (and await it)
  - Cancel a work item
  - Deal elegantly with any exceptions thrown by a work item

An` ideal solution` would be to have the Enqueue method return some object giving us the functionality just described. The good news is that a class already exists to do exactly this—the Task class, which we can generate either with a `TaskCompletion Source` or by instantiating directly (creating an unstarted or cold task):

```c#

public class PCQueueOptimize : IDisposable
{
    BlockingCollection<Task> _taskQ = new BlockingCollection<Task>();

    public PCQueueOptimize(int workerCount)
    {
        // Create and start a separate Task for each consumer:
        for (int i = 0; i < workerCount; i++)
            Task.Factory.StartNew(Consume);
    }

    public Task Enqueue(Action action, CancellationToken cancelToken
        = default(CancellationToken))
    {
        var task = new Task(action, cancelToken);
        _taskQ.Add(task);
        return task;
    }

    public Task<TResult> Enqueue<TResult>(Func<TResult> func,
        CancellationToken cancelToken = default(CancellationToken))
    {
        var task = new Task<TResult>(func, cancelToken);
        _taskQ.Add(task);
        return task;
    }

    void Consume()
    {
        foreach (var task in _taskQ.GetConsumingEnumerable())
            try
            {
                if (!task.IsCanceled) task.RunSynchronously();
            }
            catch (InvalidOperationException)
            {
            } // Race condition
    }

    public void Dispose()
    {
        _taskQ.CompleteAdding();
    }
}
```
In `Enqueue`, we enqueue and return to the caller a task that we create but don’t start.
In `Consume`, we run the task synchronously on the `consumer’s` thread. We catch an InvalidOperationException to handle the unlikely event that the task is canceled in between checking whether it’s canceled and running it.
Here’s how we can use this class:
```c#
var pcQ = new PCQueue (2);    // Maximum concurrency of 2
string result = await pcQ.Enqueue (() => "That was easy!");
...
```
Hence, we have all the `benefits of tasks—with exception propagation, return values, and cancellation—while taking complete control over scheduling.`


# Producer-Consumer Scenario
```c#
   BlockingCollection<int> buffer = new BlockingCollection<int>(5);
        Task producer = Task.Run(() =>
        {
            for (int i = 0; i < 10; i++)
            {
                buffer.Add(i);
                Console.WriteLine($"Producer added {i} to buffer");
                // Thread.Sleep(500); // Simulate some work
            }
            buffer.CompleteAdding();
        });

        Task consumer = Task.Run(() =>
        {
            foreach (int value in buffer.GetConsumingEnumerable())
            {
                Console.WriteLine($"Consumer got {value} from buffer");
            }
        });

        Task.WaitAll(producer, consumer);
```
In this example, we create a `BlockingCollection` with a bounded capacity of 10, and start a producer thread that adds 100 items to the collection with some simulated work in between. We also start a consumer thread that removes items from the collection using `GetConsumingEnumerable()`, which blocks until an item becomes available and also signals the end of the collection when the producer thread is done.

# Concurrent File Processing
```c#
BlockingCollection<string> fileBuffer = new BlockingCollection<string>();
const int MaxConcurrentWrites = 5;
SemaphoreSlim writeSemaphore = new SemaphoreSlim(MaxConcurrentWrites);

// Producer thread
Task.Run(() =>
{
    foreach (string filename in Directory.EnumerateFiles("input"))
    {
        fileBuffer.Add(filename); // Add filename to buffer
    }

    fileBuffer.CompleteAdding(); // Signal end of buffer
});

// Consumer thread
Task.Run(async () =>
{
    while (!fileBuffer.IsCompleted)
    {
        string filename;
        try
        {
            filename = fileBuffer.Take(); // Get next filename from buffer
        }
        catch (InvalidOperationException) // Occurs when Take() is called on a completed collection
        {
            break; // Exit loop when buffer is complete
        }

        await writeSemaphore.WaitAsync(); // Acquire semaphore
        try
        {
            using (StreamWriter writer = File.AppendText("output.txt"))
            {
                string content = File.ReadAllText(filename);
                await writer.WriteLineAsync(content);
                Console.WriteLine($"Wrote file {filename} to output.txt");
            }
        }
        finally
        {
            writeSemaphore.Release(); // Release semaphore
        }
    }
});

```
In this example, we create a `BlockingCollection` without a bounded capacity to hold filenames read from a directory. We also create a `SemaphoreSlim` to limit the number of concurrent writes to a file, and start a producer thread that adds filenames to the collection and signals the end of the collection when it's done.

We then start a consumer thread that reads filenames from the collection and writes their content to an output file with a limit on the number of concurrent writes using the `semaphore`. This ensures that the file writes are synchronized and the order of writes is maintained.

# What differences between BlockingCollection and concurrent collections?

`BlockingCollection` and the `concurrent collection classes` are both thread-safe collection classes in C#, but they differ in the way they handle blocking and concurrency.

`BlockingCollection` is designed specifically for producer-consumer scenarios, where one or more producer threads add elements to the collection and one or more consumer threads remove elements from the collection. It provides blocking semantics, meaning that if a consumer tries to remove an element from an empty collection, it will block until an element becomes available. Similarly, if a producer tries to add an element to a full collection, it will block until space becomes available. This makes it a useful tool for coordinating the communication between producer and consumer threads, as it allows them to wait for each other without wasting resources by continually checking for availability.

`Concurrent collection classes`, on the other hand, are designed to provide high performance concurrent access to collections from multiple threads. They use lock-free algorithms to ensure that multiple threads can access the collection concurrently without causing race conditions or deadlocks. `Concurrent collection classes`, such as ConcurrentQueue, ConcurrentDictionary, and ConcurrentBag, do not provide blocking semantics like BlockingCollection. Instead, they use non-blocking algorithms to handle concurrent access.

The `key difference between BlockingCollection and concurrent collections `is the way they handle blocking. `BlockingCollection` provides blocking semantics to synchronize access to the collection, while `concurrent collections `use non-blocking algorithms to allow concurrent access without blocking. If you need to implement a producer-consumer scenario and want to synchronize access to the collection while allowing blocking, you should use BlockingCollection. If you need high-performance concurrent access to a collection from multiple threads without blocking, you should use a concurrent collection class.